Speaker 1  0:00  
In anyhow. So I introduced logic model, and then I thought that I'll show you a real example. And I showed you the cell for example, and I was told that it was too complicated. It was a feedback and see, was it too complicated? I thought it was such a simple model. But anyway, I will have a simple section three of this section. I went to Section whatever it was before the outline, I jumped to section five. So bring up back to section three of the second lecture, and then, and I will go to a very simple example. So my objective is, the objective is to teach you how to estimate a simple logic model, just a logic model with utility functions. It's your middle equation, and the utility function are linear in the barometer, because utility functions are like beta x, kind of specification. And then simple logic model. Let's try to estimate it. And I'm going to show you very simple data. Suppose that we have 21 observations, you know, the 21 observations. And so from one to 21 and our two alternatives in the Super logic model. So for combining and the alternative are T and a T for transit, a for auto, two, between concept and auto and the explanatory variables axis, there's only one which is the total time, time in Auto, and time advance it. So the alternative is a name of the relative. One is called Auto, that one is called transit. And then so the as I told you, the name of the relative is like an attribute. It's transit versus auto. It has a lot of information. And then we have something. So this is like a categorical attribute, but then we have an attribute which is time and for the two alternatives. So observation, one, double time by auto, is this? Double time by transit? Is this 10 minutes, and the choice is transit. Second, observation, this is double time by auto. This is double time by transit. It takes longer, but this person still select, why? Because transit is, you know, cheaper, don't they get don't have to park, etc. So any other these other observations, these are all made out data. I just did an example, an example of how now we want to estimate a binary choice model. And so first we need to specify the model only alternatives. Everyone in this 21 observation is a choice between other and transit. And so we need to specify utility function. So we have two attributes, the name, the label, and the double time. So assume that the coefficient of double time is beta one, and then the dummy variable will be because we have two categories. We have one alternative is the base. So we select Auto is the base, and so the value of this dummy variable is zero for auto and one for transit. Therefore, in transit is the coefficient of this dummy variable is a zero. So that's it. That's a utility function, and the objective of the estimation is to estimate beta zero and beta one. These are the unknown parameters of this simple binary logic model to one way of presenting the model as a specification is using this table. When you have labeled alternative beta zero and beta one is the two unknown the value of the first column is the damage variable one, if times x zero if Auto and beta one if double time by auto and double time by transit. So you want the utility function for you take your photo, beta zero times zero plus beta one times time by auto times it's beta zero times one plus beta one times time. Now this is called a generic double time because it is a continuous variable, we can actually have two separate coefficient, beta one and beta two. So that's a key choice that you can make. And and how do we create this column? We essentially interact this attribute of double time with a label. So so this is double time if order zero otherwise, and this is zero, and if order and double time if transit. So you can think about these. Now here we have one attribute, which is the label of alternative, and then we have double time. But now we interact with double time with the label, and it's called alternative specific. So we now have the coefficient of target time. It's not just one coefficient. We call it beta one, but we have two, one and beta two. So in other words, the utility of photo, and this specification will be beta zero times zero, beta one times double time by auto plus beta two times zero. And so the coefficient of target utility that this utility of target time, you know this specification, beta zero. We don't know which will be positive or negative. We don't know, but it has an interpretation. If cover time is the same, then beta zero will be which alternative, then it will be positive, otherwise it will be negative. In this case, now it's different, because they say, well, a minute in turns, it is different from the minute in auto, because in auto I can, I don't know, privacy, and quiet and and so beta one and beta two will be negative, because travel time is a bad but to make less travel time, but they will maybe different, depending on how good is transit. Is it like a luxurious bus? I don't know. There's alternative amenities, or is it a crowded bus or the cloud the time? Anyhow, so beta one and beta two reflect the perception of travel time, or the evaluation of travel time, which is no difference evaluation for minutes and alternatives. So this alternative, I will stick to the simpler one. Why? Because I want to show you the results, so it's easier to show when you have only two parameters. So I'm going to show you the estimation of this model, but there's always this is a special case. You can have this model and test whether beta one and beta two are equal. It's a very common test that one wishes to do is, should I include this alternative, specific or generic. This means, and here it says, well, minutes are different. So, so this is a special case of a more general model that we can do a T test or like relational test. So now we want to apply the model. So if we know, we don't know, beta zero, beta one, so we just write them as beta so for individual one, the first observation selected transit, the utility for individual ones can delete it like that. You just input the target time. Now we have the choice is transit. So we are using a logic model. This will be the probability integral two you have this ability utilities and selected transit, and then we can write this for every observation in our data. And this is the probability of the choice and identity. And what we would like to have, because this person selected transit, you would like this probability to be as close to one as possible. Same units we want to be this as close to one as possible. And so assume that beta zero is a positive point five and beta one is negative point one. Then for individual one, if you go back to what we just calculated, these values is probability of transiting point 41 so good model. But these parameters, when applied to the individual two probability, give us point 13. So the model is not doing well for individual two with these parameters. So how do we select the best parameter? We're going to do maximum likelihood. What's the maximum what's the likelihood? The likelihood is a joint probability of the observation. It's supposedly these two observations. I would be calculating the likelihood we multiply the two one times point 13. So we're saying that for these values of the parameter, beta zero and beta one, the likelihood is point 13. Can improve it? Maybe, yes, maybe not. We'll find out. So we're going to do it for all 21 observation, multiply all this probability. These are the chosen alternative. So this will 21 selected the auto So anyhow, you put in all the numbers, we get this number, very wrong number that the joint probability of four, assuming that the beta equal to point five and minus point one. And so in general, we like look at this product. It's a product of the sample, because we assume that the observations are independent. So we have a product of the sample, and it's either the probability of order or the probability of transit depending on the choice. The choice is denoted by this Y. We could call it y equal to one if the choice is order, y equal to zero if the choice is transit. So this is just an equation. When I applied to my data, if I want to calculate it function of a beta it's a function of beta zero and beta one. And for a particular value, it's a beta zero, beta one, we get the value. And the objective is to maximize, find the value of beta zero and beta one, then maximize this function. Because this logic model is beta zero, beta one, and this is a logic model, etc. So, so L star is called the nitrogen, and we can calculate it. Remember, for for this value of beta is point five and minus point one. We calculated this value and, and, and it's, it's a number between zero and one, but it's very small number and, but it's allowed just to follow those right, slightly larger than this one, right, but much larger than this first two. So, so the question is, how do we find the magnet? And so we can show it first graphically. So, so this function is a function of beta zero and beta one. If you brought beta zero and beta one, we get this. So get that this, this likelihood function looks like that. It does have a maximum. We can find out it works over here, or someplace, not far from point five and minus point one. And so that's see that it's all small values, but that's the shape of this function. But if you zoom in, if you zoom into this, to the summit here, you find out that the summit is well defined along the dimension of beta one, but if you look at the direction of beta zero, it's kind of flat. It's not, it's, it has a maximum, but it's, it's not very sharp and and this will this mean? What does it mean at the maximum, the first derivative is zero, and the way we will calculate the maximum is apply the first order condition. So the gradient of the likelihood at this point will be zero, but the second derivative, the derivative of the gradient and the second derivative here the gradient, the gradient doesn't change much. The second derivative will be small. When it is sharp, then the second derivative is large. That's why the second derivative give information about the standard error. How well can you estimate it? If you have a sharp peak, then the estimate is more precise. So we want to find the value of beta, beta mean, beta zero and beta one that are more likely to we want the likelihood

Speaker 1  8:31  
function already. So in general, we can have a vector of betas in our example, derivative only two for binary choice model. That's the way we like the likelihood function. But in order to maximize it, in order to calculate the derivatives and find the first order condition. Second order, we will take the form. Remember this, we had maximum likelihood, so we take the log of this function, and then we will maximize the log likelihood. So we denote that the likelihood is L star. It's a function of beta and the log likelihood is just L capital L. It's also a function of betas. And the maximum likelihood estimate, we can maximize the log likelihood because it's a monotonic transformation. So the maximum of the likelihood maximum of the likelihood and the maximum of the log likelihood is the same maximum likelihood. And so that's the problem that we need to solve. Find the argument beta that maximize this log likelihood function. And so now we'll apply this to the logic model. The logic model, the log likelihood, is just a sum. Instead of all that, we have a sum of the sample of the log of the probability of the chosen alternative. And if we we can write it as a chosen alternative is denoted by y. So we can just take the log of the probability of the choice for the chosen alternative. This is the model. Remember the logic model. We are going to assume that mu is equal to one. I'm going to have a simple logic model linear. The V's will be linear in the unknown parameters, and the mu is equal to one, which is a standard normalization. And so the log likelihood actually can be written as this form. You plug this into this equation, we get this equation, and then we take a derivative. I'm not going to go through the detail, but this is again repeated the same function the log likelihood for a logic model. This is linear in the parameter. Logic model, we differentiate with respect to the angular parameters, beta. This is the first derivative, and this is just a set and equal to zero. So this is the first order condition in a compact notation. This term here, just replace it with P. Is beta hat. So it's a, it's a, it's an X times the probability, and it's an X times the y. So you can just write y minus this probability multiplied by x. Notice that this is a similar position. The first order condition gets a condition we had for central times x equal to zero. So this is like kind of procedure. It's not exactly the same. Y is y1 of zero, and B is the number between zero and one. So, anyhow. So this logic model is why it's the simplest kind of discrete choice model. Logic, linear and angle parameter, scale parameter normalized to one is of the first order condition. Now, the difference between this and regression is that this is a non linear function of the base of the beta. Now, exponential, the heel. So and in, in them, in in, in regression, this was a linear function, a system of linear equation. We have an equation of this for every k, right, for every k, we have an equation like this. Because this is a system of equation in regression, there were linear equations. The objective function was quadratic. We took a derivative, we got the linear. Quadratic is beta. We took a derivative. It was linear, and we can solve it by inverting the matrix here we cannot. This is not linear in the beta. It's not we have a system of equation which are non linear in beta. So we need to solve this system of equation and and so we are looking for a maximum. This just to tell you that you know that we are seeking maximum cannot be better than zero, because it's a likelihood is a number between zero and one. The log likelihood is a number between minus infinity and zero. So the maximum of the maximum of the best, if you're like the perfect elected, is one log of one is zero. So this is zero as a perfect volume. And then we try all different values of betas, and we are looking for the value of beta head that maximize right? That's what we and it will be somewhere between the starting point. What's the starting point? Starting point, we say, suppose that all the betas are equal to zero. If all the betas are equal to zero, it's equally likely like flipping a coin. And so that would be the starting point, like a benchmark, and I will not escape this. You can go through this with yourself. There's another kind of benchmark which says only constant, I ignore it, but now I have a system of equations, and again, a nonlinear system of equation. The solution is you learn it in high school called Newton's method. Is a kind of basic method all kinds of collaboration or variation of the Newton method that all of you have learned, you must have learned it before. And the idea is, it's iteration. Basically, you get a starting point, you linearize the function. So you take it from system linear equation, you can make it linear equation, and then you linearize using tables. You linearize it, you get the system of linear equation. You solve it, get the new solution. You take the solution and now linearize the guy around that solution and keep doing it. So that's that's integrations for solving the system of equation. System of equation we obtained by taking the derivative of the log, like Newton says it's equal to zero. This means the first order conditions and and so Newton has designed to identify a local maximum, because it may, if this iteration will find the solution in which for this equation, but because it's non linear, it may have multiple solutions. Linear function can cause zero multiple times, and so that's why it says it is designed to identify a local maximum. But when you saw the shape of the likelihood function, we saw it as a nice shape, as a unique maximum. A unique maximum occurs when the function is concave, like so in our case, in this case of binary logic Union, in the parameter model, we can show that it is globally concave, meaning the function doesn't this nice property of so that you identify the maximum that you identify, it is global, unique maximum. And so the method calculates derivatives. So with an objective function, you calculate the derivative. Sometimes we calculate also the pure given method of second derivatives. The equations based on the first derivative, the linearization means that we have to calculate second derivative. So you have an objective function look like we need to calculate first derivative, second derivatives, and then iterate. And so the package that we are going to use, and we are going to use Biogen, and it all will be it's a kind of standard routine that exists that can be used so, but it takes time to converge. So unlike regression, where we just linear models, in general, where you obtain services of a linear equation, just invert the matrix, and you have a solution. Here you have to iterate, and so you always need to worry about convergence. How long does it take? It? Does it converge to the unique solution? And suppose that you have a regression case, and regression case supposed to be a situation where there is multiple perfect, multicollinearity, and you'd like to invert the matrix, because you the matrix, you get similarity. Same thing would apply here, if there is multicollinearity, like what will be a multicollinearity here, if, instead of having one damage variable, only for countries, including the second diameter, also for auto, is two categories and include two damage variables, then, then the question the model will be singular, meaning that the function has a flat top, maybe there's infinitely many values of these two parameters in the space of these two coefficient there are many possible infinity possible number of cognition so that we should be single now. So if it is, if you have a situation like this, you are insulating, and you you find the maximum. But the maximum is not unique, because the top of the mountain is flat. There many possibilities, so conjunction or even fail, because if you want to say you don't find the maximum, but the model still kind of takes you around this platform, and you find other solutions that have the same maximum. So it doesn't it depends. Some of you have differently in this kind of situation. Some tell you you've you've converged because you find the maximum. But as I'll say, No one but the maximum is not unique, so the mode of signal, okay, then some parameter defined the second this is indicate the second derivative. So if you calculate the matrix of the second derivative, and if the matrix of second derivative is singular, that's when you have a plateau. And if it's not singular, you can infer it, then there is a unique maximum. And if you want the correct likelihood function. So this is a bound. It's an estimate of the grammar law bound, and it's a concern for the consistent estimate of the trans covariance matrix. Most methods are sensitive to the condition of the problem. What does it mean? You're doing the other matrix, and they also doing the matrix, and you linearize them all in compliance to find the solution. So if the instance close to COVID 19, it means that this inversion is problematic. And this kind of inverted, it becomes very large. And so most methods are sensitive conditioning of the problem. And one condition problem is a problem for which all parameters of almost the same magnitude. So it turns out that if, if you change the unit of observation such that some of the betas are very small and some are very large, then there will be landing offers. And so this means a good practice is to give units to the beta to the x's, such that the betas are not about and this will help in the same version. Okay. Now just to show you, to demonstrate this algorithm, and we start from 00, and I mean, this is like a view from above of like low likelihood function. The maximum is somewhere here. Let's see how do we find it? And so we start here. We calculate the gradient. It points in this direction. That's the derivative of the log likelihood. And so this becomes our next point. From here, we calculate the gradient. We go to this point and so on. So this shows you the iteration and and then we convert here to some number here, and here roughly near where we were before, I guess, yeah, and that's how the so for simple logic model like this, you see it took, I don't count with 123456, that's typical, a typical kind of number of iteration. If the model gets bigger and bigger and more complicated, it may take more and then some. So this is Emily. You know, the properties of Emily, these just repeat, seem to be normal in the general case for non linear model. In the tablet example, we had an Emily, which was, you know, unbiased and efficient. Here we only have a general non linear model, and so we know that it is consistent. It's asymptotically normal and asymptotically efficient. We know the kernel row bound. It's based on this matrix of second derivative of expected value and this is our estimate of by calculating the second derivative at the open solution. And we get, we get this matrix V, we invert it, and then we have the variance, or the square root of the diagonal, are the standard errors of the s1 where you calculate the standard error of the taking the square root of the diagonal element. So when you have outputs, you get the beta hat and arrows, which are the square root of the diagram. That's it. That's estimation. And the next section I covered last time, I will not go through it again, for example. And the last section is evaluation, estimation results. Please go for it yourself. It's the same as in English, except that so t test, it could be like relational test that we already talked about. We can calculate the goodness of fit using how much of the log likelihood was explained relative to a benchmark, and we call it a square more about it in the next lecture. I don't know about this, and I'm going to conclude this lecture any questions about logic and how you estimate the logic model. And we saw a real example with this telephone data already last time. Any questions here, zero. Bega means 5051.

Speaker 1  18:14  
I'm sorry, no, but you're doing the normalization right. And the question is, what impact if I do another normalization? Because we have utility functions, we have to give to the utilities a scale in order to be estimated. So the square is arbitrary, right? And so setting mu equal to one is essentially, is kind of a typical normalization that says I'm fixing the variance of the of the epsilon, that's all and it is reflected in all the parameters. So, so if a scale will be equal to u, you can take all the beta and divided by two. So this model is is as simple as possible when you equal to one. That's often most software packages just do that. Now. What happens if, instead of normalizing you, you normalize some other parameters? It's possible, and we can do before I mentioned money method, utility will come to later, but it introduces some non linearity, additional non linearity to the utility function, because the utility function will now, because you have products of parameters, so it's but it really has no problem. So any normalization is okay, it doesn't change the model. Remember, restriction on the model changes the model. So we have a general model. Sometimes we post restriction, we get a special case. Normalization of a model is something that you do that should not affect the model. That's why I call it normalization. Why is it? You know? Why do you need to normalize? Because everywhere in the model you have mu times beta, mu times beta, mu gets multiplied all the beta, so you cannot separate it. So you have to normalize either one of the beta or the mu or some other things. Okay, like, for example, you can say, I can want the sums of betas to be put one in organization. Why would you do that? I don't know. Some people do that. Okay, any other Yes, go ahead. A condition of a matrix. When you have a square matrix and you want to invert it, if we if you have linear dependence between columns, then you know it's close to singularity. The determinant will be small and certain conditioning. So when the determinant of the matrix is very small and the matrix is said to be in condition some close to dependence among different

Speaker 1  20:18  
columns, suppose that you don't have lots of the political linearity and and then it turns out that does very different if x is a very different scale and the beta sub beams are small, that the matrix it starts is not as well conditioned as it could be, and therefore it can lead to Angie. Yes, the coefficients scale is defined by the variable is the variables, like, if, if, if you have good distance variable, and one is in kilometers or miles, and one is inches, and the parameters, therefore would be very different. So keep everything in this change the scale, because you're free to change the scale of x's. So I can then measure distance in miles or in inches, or in 10s of 10s of miles, or in hundreds of my units. So you can decide what the units of x's, thereby you are affecting the magnitude of beta. So it's a good practice of regression. And in any kind of multivariate problem that you have suggested undo parameters you would like less unknown parameter, very different, because if you don't affect the derivative, if I differentiate, if a beta one, okay? Explain it, but I just go into another time about things that I have to explain. But this is a good practice. Is whatever you do in regression or skill choice model, just if you see betas that are very much different, saying, could they go to the access and just change the units? Could they change, you know, cents to dollars and dollars per cents and something like that, okay? And because it's changed the magnitude of the fact that any other questions. So I want to leave some time today to another topic. And so this concludes the kind of the basic part of this great choice, logic model, linear in the parameters. Escape parameters with one we have maximum record estimator. We applied it to the telephone data. You can apply limit on the number of alternative, no limit really on the number of betas that you can have, you can have. But they show this very simple example, but it can be logic model, same as a question. There is no limit to regression on how many observations, on how many parameters, n has to be greater than k. That's, of course, obvious, and minus k the same, same. Again, estimating a logic model, you want to have a number of observations greater than the number of fundamental parameters. And so once we cover the basics, we are more or less approximately where we are in some place in regression. And then you can go ahead and apply estimates a logic model and analyze the parameters, etc, and so on. That's what we wanted to do. But one question that often comes up, and so the rest of this lecture today is for the same aside question. Forget about statistics. Forget about significant there's a simulation of likelihood. I want to apply this model, and we've applied it to the choice of individuals, but I'm interested in predicting aggregate demands. So we distinguish between two kinds of prediction situation, the prediction situations that are usually nowadays online applications where we predict for individuals. Individual come to my website if I want to predict what this individual is like to have, or prefers the predictions at the level of a person. But for a lot of planning, a lot of pricing studies, we're interested in the behaviors of groups of decision makers, and so they call it aggregate forecasting. So how do we do aggregate focusing? Because the model for choice a positive is the framework of an individual making a choice. In the regression case, we had the dependent variable y, sometimes is only going to estimate. If not, we have the average of y, or y could be an aggregate quantity and sum up y at the same here we have this, but we'll never forget about it. We'll see in a moment. So there's a slight problem here, because of the non linearity. So this lecture is what happens when you sum up individual to make an aggregate forecast, trying to find aggregate focusing and then say, well, if I want to calculate market share, can I just take the model and substitute averages? And the answer is no, yes for linear model, linear in the variable, but no for non linear model, including Aggie. And so this is like the idea of an average individual, but our techniques, which are based on sampling and simulation, that allow us to overcome this non linearity. And I'll explain and so this is what this lecture is about. Actually, if you look at the topic for this class, you see that there are two decks. One is this defined problem, which is very simple problem. I'll explain it. And hopefully in order to deal with it. But there is a side technique that I will not cover in class. It's exactly called the iterative proportional fitting. It has a related application. We can talk more about it later if you have time, but I'm not going to be able to cover it's because it's totally related in terms of methods. But it's very useful technique to have for to do simulation. Okay, okay. So realizing people are changing policy and demographic, you want to make an aggregate prediction, but we have a disaggregate model. The model is aggregate because it's predict for giving the figure n is an individual xn l characteristics, and aggregate for individual. And if you're interested in an aggregate demand, we just need to sum up if this is if our n people in the consumer, say, in the population, each one has a probability. If you want to know what will be the total demand, we just sum up this probability, and you get expected demand, right? So they are going to default the same would always involve some sort of some like this, over the population. But here is a problem. I have a sample. I don't I mean, if I want to estimate for the entire population, then you say, can I just include average of x? And the answer would be, no. That's the problem. Okay, so that's the definition of demand. And so if you have a population for each you can think that, assume that the value is the same. Number of alternative, we can predict these probabilities which individuals are different, and then we just sum up the columns, and this will give us a demand for an alternative. But the This means, this calculation means that we know the x value for each individual in the population for which we are doing the forecasting. So this has nothing to do the estimation. I'm not talking and applying the model. I summarize the sample of the observations. I estimated the model like my telephone example, and now we want to apply it to the entire population. Let's you know by that definition. So the aggregate demand, and if I want to calculate the share, I just calculate the Aggie demand divided by n, and I get so the share is the average of the probability, simple average, because we calculate it for the entire population. And sometimes we do it by market segment. So we do it by market segments. So we don't do it on the entire population, so we serve the show for tentative I in market segment. G is the same. It's a sum of the entire membership divided by the number of observations in the market segment. Is this invitation someone? Or is this a i was just touching it. Okay? Anybody else wants to search? Go ahead. Feel free to search if you see me. So I there's a problem. So as I said already, the problem is all these sums of the populations. Angie implies that we know the x for every member of the population, and we don't even know the averages, right. And so in this case, let's do this average, difficult idea. So suppose that we have two persons, or two types of persons in population, type one and type two, and suppose that x, suppose that x is equal to point five for type one and two for point two. And suppose that the model that you estimated is this simple binary logic model. And for this value of x, we get the probability of point six. Two, for this type of person, we get point 88 and now suppose that we say, what would be the aggregate share? It will be the average of these two, right? So it's average of the probability. So the average of these two is point 75 so the correct aggregate forecast is point 75 but suppose that you say, I don't know about the distribution. I would assume that the population is divided 5050 between type one and type two. So if I calculate the average x bound and calculate it correctly, it's 1.45 Why not substitute one point 25 into this model and calculate this, model we call the average individual, calculate the probability for the average individual, and it's equal to point seven eight. It's not the same. That's the problem with the nominality. If this was what it was linear in x, then replacing x with, you know, with average x would be okay. So if you have a regression model which is beta in intersect, but times beta times in the variable x, and you replace it with the average x, you get the average of y. But if it is log of X, Y equal to alpha plus beta times log of x, the average of y cannot be obtained by alpha plus beta times the log of x bar, because it's a non linear transformation. So so only this average individual method works only when the model is linear in the axis, not linear in the betas, linear in the axis, because the model of Y equal to alpha plus beta times log of x is linear in the unemployment parameters, but it's not linear in x. So this non linearity in x, which is foreign non linear model, so it's always true. So negation is not always true, but in this model, it's always true. Therefore, using this average individual method, give you a bias. This is called aggregation bias. It's equal to point 03 and the value depends on where you are on the curve. Actually, there is a, I always forget the names of when non inequality single, and it's just explanation. So if the function x, if the non linear with x, if x is concave. So if I take the average of these two points, I get the point which is below the line with the total value. I'm sorry, the true average will be below the line. And the bias model, if I substitute x bar in the model, I'll get an aggregation bias which is positive and overestimate the probability. And so depends. It depends on the curvature. If it is cocaine, I will overestimate. If it is convex, I will underestimate by substituting averages. And that difference is aggregation bias. So the selection of the and it's not a bias like an estimation so this is just an exciting the average Digital Point is here. But if I substitute the average in the model, I get this value. Distance is the aggregation bias by just using average. Okay, anybody remember the name this inequality? It's

Speaker 1  29:20  
okay. It will come to me, unfortunately, this is kind of a the inequality is just says that if you have a function, a nonlinear function, and you ask yourself, What's the difference between the average of the function versus the function of the average? Then it's either positive or negative, depending on the convexity of the function. So that's the negative inequality. Doesn't matter. It's a simple mathematical property, okay. So if the variance of x is small, then it's okay, right? Or if you applied, if you define population groups that are relatively homogeneous with respect to x, then it's okay. So what do you do when the viability of X is significant and you don't want to have bias like this, you don't want to calculate averages of x and substitute and I'll show you two approaches. One is, you have a sample. And if I have a sample for summation, I can just calculate these summations for the sample. So for example, if I have a sample, deposit is a random sample, then I just calculate an average, calculate the values of x for element in my data. And if you say, well, but I'm focusing for the future, then I need to move my sample for the future. That's why I teach you IPF. That's one way of doing if I have a sample today, but they want to focus in the future. Situation where some of the x's will be different. And the question is, how do you know the sample to do future when the composition of the operation may be different? That's this way. This technique is very useful. But anyhow, so this sample of using a sample, I can just calculate a distribution of x in my data, or an assumed distribution of x in different dimension, different value of x. Just calculate an average. And so I can do it for group, etc, just a simple average if the sample that I have has weights right. And whatever lecture coming up, we talked about something, remember when we talked about something that often there are weights. And so we can use the weights. And what is the weight? Usually measure the weight. This little omega here is the number of individual in the population divided by the number of individuals this particular group in the sample. So, that's if each person in the sample represent 100 in the population. If it's something running 100 then each of the patient is valued 100 but the weights could be different. For some in some places, for some population segment will be 100 for other it will be 1000 for something to be 10. So we have these weights, and in Formula, when we have these weights, when you can calculate weighted average, that's just a formula for weighted average. So the predicted channel, the aggregate channel, is just an weighted average of this probability as predicted by choice model and random sample. All the weights are equal, not necessarily equal to one. I should have said equal, but one or equal doesn't matter. The weights cancel out in so the question is, how to calculate these weights? And that's where IPF come in, and to calculate weights for the sample, you know. And often it is done by using some exogenous forecasts or exogenous data, so just the weight of a sample to reflect a situation that is predicted, you know. So this IPF, now you have the telephone algorithm time, so I'm going to be particular time. I guess maybe I can do something about like you have. So additional examples, suppose that you have this telephone example, price increase. We increase different alternative by different values. So remember, there were five plans, and the idea is that the cheap plan remains cheap. We don't increase it, but all the other plans have increased, $4, $6, $7 etc. And so this is an example where we take the data that was used to estimate the model. And so this will present an existing situation, and we can calculate fitted probability for the base case, meaning under the existing prices, and then calculate fitted probability by changing the prices are going to be like this, and calculate fitted probability for all the observations. And this fitted probability are called p hat base case. So this is observed the estimated parameters, and this is with the price increase. So we take the data that we use of the first estimation and go observation by observation and calculate fitted probabilities. So for the data as it exists, it's called the base case, and then it goes through our sample and change the value of x's. Using this we change for every observation, we increase the prices, and then calculate again the probabilities, and then calculate the average of the base case, calculate the average under the price increase, and the difference would be the effect of price so here's this example. So the base case, when this is shown by three income groups, income groups, we calculate the probabilities in the base case, and then we calculate the probabilities with the price increase. And what we should observe should themselves as budget measure will increase. So budget measure had this point. This shows it has greater shows and the others should have very complicated pricing links, but, but we know that this one, the price did not change, and all the others are more expensive. And finally, the one, the technique that is most often used and most useful. So either if you have a sample, somehow you have a sample that is often you collected it to estimate the model, you can even use the same sample. Why? Because the sample, or presentation, not only the choice, but on the x variable, except the variables, like prices you can control, but you know what the base situation you manipulate variables. And so this was a good example of sampling relation. So we call it sampling relation, and in many particles equation, it is based on the same sample that was used for simulation. But now suppose that we have a sample, and let's say it's in the Boston area, and we collected the sample of, say, 1000 individuals, and a sample of 1000 individuals is okay to predict the demand overall in say, Boston area, to do this kind of sample innovation, but suppose that No, I have more objective I want to estimate it by municipalities. And there are, like, 200 or more, I don't know, local areas, and they want to have an estimate of demand in each of these of 200 areas. 100 areas, 1000 divided by 200 gives a small sample. If I want to apply this sub relation method, there'll be some communication which I have no relations. So how do we do the focus? Well, then we will use micro simulation. So that's the idea of micro simulation. I I just create a population, synthetic population. That's that's idea. I create synthetic data, and so I collected a sample of 1000 it's not enough. Now, can I take this 1000 and multiply it by 100 then I get 100,000 observation, every bit better. But I mean, still, there may be some community in which I don't have observations. So I may want to reweight this one sample or divide them in difficulties. I need to manipulate some other they have populations. They want to create populations. Often, this is done using census data. You go to census data, so I have, I did not find some community design observations, but there are some census data for this community. So I borrowed some observations from other areas, and I create a population for this community such that the distribution that I have and information that I have for this community will be reflected in the sample. So I manipulate the weight of this observation that they take from elsewhere to create so I call it synthetic population. So a lot of application nowadays are based on this idea of of synthetic population also. And if I if I have a sequence of models, suppose they don't have only just one model, but they have a sequence of models. And I first predict what people live, then I predict what kind of house they have, then I predict whether or not they have a car, like whether or not they they drive the car. Often, they drive the gun, etc. So if you have a sequence of money like this, then and you say, I'm going to do something in relation, I have to keep track of all the probabilities, meaning, if I predict, if I take a house, predict where they live, but there are probabilities that they live in many different places. And so I create a tree. There's a tree that is going, going, going and become not particle. So it's not always particle when you have a sequence of money. So what do you do? So what do you do? You use this micro simulation. So when you have large bonuses, when you have sequence of decision. So if you're ordering the area of the driver, there are all these probabilities. If you keep from the origin, every time they have a probability going right, going left, going right lane, left lane, the tree will begin very large, because they can make decision every every few seconds. So so micro simulation is every time you apply the model, you don't keep the probabilities. You simulate the probabilities. That's ideal. That's insane. Micro simulation just simulate the probabilities. So it's meaning, it's a you have a probability of point 6.4 you just lower the number. And it is a probability point six that you select one alternative probability point four you select. So you predict the choice based on the probability. That's what we mean by realization. So for each individual, each time we apply a model, we predict the realization. If you apply regression model, then you also sample the epsilon, because y equal to the function of x's plus epsilon, so you calculate the function of x's, and then you sample from the epsilon, and you get a realization of y. For this great choice model, you just predict the probability one of the outcomes for each person, negative probability distribution, so Y, I N has one initialization for n is alternativeized otherwise. And so if you have a model, you have a very large population for each element of the population, for each member of the population. You apply the model, you predict the probabilities. You sample from this probability one realization, and then you sum up realization to calculate the shows. It's like working with conventional data. If you want to do a survey, you observe a choice. Now you predict the choice, not just the probability of probability of a choice, but so that's the idea of micro simulation. And so that's just an example. Suppose that, how do you do that? Now, they suffer from the probability. Suppose that they have, suppose that they have probability. Black is forgetting if you don't make something the excess of such that they get this probability. So alternative. And so the question is, what's the choice? And so I draw a random number. So every computer environment will have a possibility to go random number. And another number is draw from a uniform 01 so, and it's a number between zero and one with a equal probability from one to zero. That's a uniform that's a uniform 01 so it's a distribution that is equal to cos interval zero to one. And so you get the number. And so suppose that the number is point 52 and the probability is where point five, point 2.3, doesn't matter what the order is, you can arbitrate. And so you have point five, then point five to point seven, and then point seven to one, right? So if your number is less than point five, you declare the right is another number 22 is this interval. Declare the choice is work. And in this interval between point seven and one, you declare that the choice is fast, that's it. And if you do it, if there were, like, you know, 1000 individuals with the same probabilities, then yeah, it will be the shares will be 5020, and 13. If you have to sample this version of this idea. And then so it does. This method means you require a lot of samples. So sample demonization is efficient. You use the probabilities. And so you can do it with a small sample. This idea of micro simulation require a large sample. That's what I'm saying. It's often done with synthetic population. You create millions of ways. It's all done by computer lines. And so that's that's basically all I have to say about that. Just a conclusion, and I have few minutes, maybe I can talk about IPF unless you have questions, go ahead, simulation versus the sampling of steering sample innovation. If you can do something innovation easy, it's easy to do, and that's the standard approach. Micro simulation is usually for a bigger project, with more ambitious model, complicated models, more ambitious focus. They need to buy small areas, a small population. Then you do micro simulation

Speaker 1  39:22  
where you're complicated model system, like when you're predicting for a sequence of models. So I'm interested in predicting people that make ownership, but they just have to predict where they live, then what the income will be with a sequence of modems maintaining the probabilities and creativity, complicated three, yes, synthetic population. When you discuss your data, use regards to No, I mean census data, and gives you data into some aggregation by block size, by block face, or by Census luck. So if I want to make a fair performance I will get aggregate data from the census, and I would like to use this aggregate data to weight a sample that will reflect the population of that census tract. So the question is, what do I get this individual? But I'm going to wait. You can get it from a sample collected or the census, the US Census and other Census Bureau maybe do it as well. They release a public use or data where they hide the location of locations given only by county or by and so you take individual observation from from the entire Boston area, and you say, Okay, let me take a sample of them and reweight them for my sensor. Start to reflect the data that I have for the Census part, using IDF, I can calculate these weights and then apply either sample relation or micro simulation. But this idea of synthetic population? Yes,

Speaker 1  40:51  
because for the synthetic population, I don't know the choice, right? I'm predicting the choice. So this lecture is not about statistics in the sense of statistical inference. It's applying the model. This is very plain. Is very practical. Basically, this block of different, very different lecture is about practical issues. I mean, same problem that you will encounter for which you need methods. And so this, you've done the estimation, you've done the tests and the interpretation, and you get the model that you're happy with. You know, I'm trying to apply it to calculate optimal advice to calculate, and I don't know, you know, how to calculate the demand for different if you're predicting for you do need to have information also the other of course, generate those based on

Speaker 1  41:40  
is, yeah. So, so the population representation means characteristics, right, but it also means access to alternative because one of the characteristics is location. Location means, when are these people in the in downtown Boston or in the suburban area? They may have access to different products and services? So, yeah. So you predict the population is our characteristics. And then the choice sets used to be created, and the other user forgot to the choice set. It could be created

Speaker 1  42:11  
as well. I have three minutes taking three minutes to change the deck. So, I mean, the deck is there for you, the IPF. I advertise it again and again. It's extremely simple. You may encounter this technique already, and it's very, very useful. There's an example there that is done with the spreadsheet program. It's typically, it's kind of very useful. So basically, to explain it in very brief language, suppose that you have a tablet example, and you have entries in the cells, and then somebody gives you future focus of the raw totals and the column totals. So that's the simplest application. So I can show I click this slide, you have a table, and then you raw totals, these raw daughters, and you column buttons, and they want to fix the entries in the table to reflect the new tokens. That's a standard application of IPF. And you just go row by row, scale up or down, then column by column, you iterate, and if there are no zeros all, this is an intellectual it's zeros that are problematic. It guarantees to converge. And essentially, that's how you get weights. Because I have samples, and I want to focus on the change in income, changing the education, change the distribution weight sample, one more minute before we get kicked out, I Okay, so what's coming up next, the next lecture is back to Statistics but and we come up with a good model good model specification, and then we'll talk about also endogenous and there's another topic on sampling, like that we'll get to in so we have two more lectures in this book.

Transcribed by https://otter.ai
