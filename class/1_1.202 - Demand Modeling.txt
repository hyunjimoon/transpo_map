Until June, the month we will begin at 105 and do my best

so the lecture is being videotaped by the sign, so you can watch it also on video. And the every lecture, their slides, the slide will be posted will be available on the class website. And on

the website,

so the

slides and slides will be available on the website, and if you have accessing the website

assistant, and so one of them connect will get access to the website and became here the beginning of every lecture I'll have on my slide to see now which is a plan for this lecture. So the other for today is two main parts. First, an introduction to the course in which I will go through these syllables. It's available on the website, so I'll talk about the syllables, and just to use an equivalent in case of any questions, and then I have any connection to the course, just give you a flavor of what your COVID What is the material that we cover in the course? And the unique aspect of this course, as opposed to other statistical influence or aggression or econometric is a focus on discrete choice. We're not only covering discrete choice, but discrete choice is the main focus of the course. And you'll see from the plan for the semester that we begin with probabilities, statistics, regression to prepare you for this great choice. So we'll get to it eventually, but once we get it, it is the focus of the course, and say more about this great choice in a moment. So that's the purpose of today's lecture. Just give you an overview of the course, the syllables answer any question that you may have, and show you the plan for the semester. So you are here so you know what this course is about. It's fueling application of modeling and statistical method for analysis. The key world is analysis, more so than focused, but of demand for facilities, services and products, all kinds of applications. My academic domain is transportation, but I've worked on applications in many other areas, and of this great choice. And so this cost is therefore it's not the transportation cost. You'll see a lot of my work, application example, data, it comes from transportation. But I talk about the case study at the moment and and that's the key here. Another key aspect of this course are the case studies. So in addition, every week, we have two lectures and we have a lab session. The focus of the lab sessions is on these statistical software and data, real data, so that you can do actual estimation with real data using software that you can use later, free software that you'll get access to. Okay, so that's the plan for the semester, and in terms of blocks of material. So as I said already, I'm after this lecture is introduction, and then we have a review of formulating statistics lasting for four more lectures. That's a number of lectures. So that's the first block in the class. Second is about linear regression. I just don't want to go into non linear, this great choice, modeling without knowing basic regression. Some of you may know it, but I think you should still participate in it, because even if you had it before, because I think that would be a way to understand what expect, what expectation are. How do we approach statistical models, etc, and so, so that will be broke of seven lectures. I cover everything that is relevant from linear regression, I mean the regression, the extension to non linear, is kind of straightforward. Next we go to discrete choice. So we have two lectures on the fundamentals, and then we spend three lectures on something called practical issues in building and applying models. I see you'll see more detail on these lectures in a moment than because of the syllabus. Then we go back to discrete choice, and then we have another very important work, which is called logic picture and stated preferences data and what is the application of discrete choice is to estimate how users react to multiple features of products and services, and estimate and the preferences often is estimated by something called willingness to pay how much? Because every time a user come to participate in utility costs or effort, it has to be invested in it. And the question is, how do they assess the value of utility or the attractiveness of the preference for different features, and for that very often stated preferences are collected. I've explained what this is, and there are models that coordinates that are useful to assess to estimate these values. And finally, two lectures of machine learning, one machine learning regression and the other one, machine learning at the stage was but this will not be the case studies. The case studies, I don't have to list here. The case study will be for each block of each block of material. There will be a case study, except there will be no case study for block seven, so be a case study zero. Case study one. Now, if you go to the syllabus after cost, description, requirement reading, there is a section called Computer Lab case studies. So as I said, as a key feature of this course, and six case studies are listed for six drugs, and the first one is called case study zero, because we just checked it more to make sure that you understood the review part of the course. But then two case studies on linear regression, and one case study on the logic model, how to get forecasting, another case study on extreme value models and class of these discrete choice models. And finally on logic picture, also using State Department, state so these are the case studies, and these are the subject of the focus of the elicitation. So we have two lectures every week, as I said, at 1052, 25 the lectures, I believe in the lecture slides, there'll be videos, and everything will be accessible. And then, in addition to our recitation, there is one recitation every week. It's Friday, and this will be ended by Angie so. And the main purpose of solicitation is to present the case studies discuss answer any question that you may have about the software and the case studies and any other material which I cover in the lecture in which you have questions. Then that's the purpose of solicitation, the one hour fighting and next on the syllabus is upon schedule. You have every lecture, every recitation, and this is listed here on the topic, so you can see the link by these blocks. And so block one introduced today's

lecture, five, total five lecture. The topic for every lecture is listed, and I think the slides already for the entire block. The slides if you want to see what's coming up, and we'll see what's in block one of the calls the slides are already the So, as I said, every lecture has a topic. It has a type of slide that I will cover in the class, but I don't guarantee that in every lecture I will exactly have time to double everything. Sometimes I will have time at the end just have a discussion or ask questions. Usually, I think that may happen, either they will run out of time but continue the next lecture. So the boundaries between lectures is kind of flexible, because it's me, I'm going to give all the lectures so I just can continue in the next lecture. If I didn't finish the day, or sometimes I'll say I'm not going to finish the day. Go ahead, check it up yourself and let me know if you have any questions. Okay, what else? So that's basically, you can see that's block one. Then you see block two, the seven lectures. The topic of every lecture is listed here. Another situation you see also when a case study, case study, 01235, every time the case study is out, meaning it's available for you, is indicated, and then when it is due, is indicated as well. Okay, so that's, that's the main, the main requirement that you need to do, the work you need to do for this course, are these case studies and midterm and the final and the midterm will be, take home midterm, as we describe here. It will be, it says when the midterm will become available. Well, if it meter exam. So that's on block three. You can see it specify that the meter will be released on March 19, and it will be due March 21, two days later before the recitation. So it will be released after the lecture on Wednesday and be available. You don't expect it to work on it for the entire duration. For when it is released, until it is due, it will be a lot short of the debt. So this will be middle and then there will be a final it comes and tell calls during the final week. We don't have yet a time during final week, but we requested the first morning of the first day of the final week, so if you're getting ready to leave town, hopefully this will be helpful Next to me. Okay? Any questions about the syllables? So?

I mentioned the requirements case studies meet the final and the weight that we use to calculate the numerical grade. At the end

of the numerical grade, we only use for ranking, and then whether I use an A, B, etc, it will be my judgment.

There's no fixed proportion or killer. So

so this concludes the first part of the lecture today. No questions about going for the

final Are you going to have the machine learning be part of the final exam, even though we don't,

and maybe I don't know yet, but unlikely machine learning is because I cannot recall modeling without talking about machine learning. Machine learning, there is a case study machine learning, but it's not in this class. It's in world class. So I teach two classes of the mind modeling. This one is the first 1202, I teach another class called 1205, which is in the forum. So the idea is that for graduate students, that the person has some statistics, then we can take this class, and then in the second year, you can take one through five and some other more advanced methods, model equation, models things of that nature, and like I have a lecture in this class about Bayesian estimation, but there's no case study on patient estimation. You learn how to teach you what it is, how to do it, what is involved, what are the key idea of Bayesian statistics is applied to discrete choice, but there is no case study on it in this class. So this class covers the basic, the basic of so that you are capable of doing the basic linear aggression or aggression in general and discrete choice. Any other questions?

Good. So next, the next part introduction to demand modeling. So, as I said when I talked about the purpose of the course, I emphasize the word analysis, as opposed to prediction, forecasting analysis. What does it mean? Mean that in order to analyze a system a policy. You need to do any kind of policy analysis or any kind of optimization. You need to understand how the users are going to react, meaning there is some consideration of a system and an intervention in this system, changing the price, changing the service, building a new subway system, doing something, building a new bridge. So there is an intervention, and the question is, what's the optimal intervention? What's the policies of government intervention, like changing the fail, changing the frequency of Celes, optimizing some service, optimizing prices, optimizing whatever, whatever else you may consider. In order to do that, we need to have a capability to say what will happen to the demand side if we have this intervention. So usually we change something in the supply and demand is going to react. And the purpose of this, course, is to understand user reaction. And so in order to do such analysis, we need to have causal model, because we impose an intervention, we need to know what the response is, and this is different from prediction or focusing in which you may not have an intervention, right? You have a system and which generates a lot of data, hopefully large data, and you have a lot of data about the system, and you can process this data to predict, to maybe interpolate or to extrapolate, but you're not considering an optimization of an intervention in the system, as opposed to the focus is on prediction as opposed to analysis, and because that's the focus, it is essential that the model to understand using the angle, because in the sense that the variables that are manipulated are causing the reaction, and that's what the model needs to Measure. And the usual basic scientific idea is to understand cause and effect is to conduct experiment. So what kinds of experimental data we have, we can do real experiment, but in many systems, it's usually possible. In many civil engineering system, transportation system, maybe financial system. It's impossible to actually conduct real experiment, because you're dealing with human beings. And sometimes the subject of experiment is not even annoying, like when you every time you go running up whatever app you are using on your telephone, or if you go to the web, you are, some of you, at some point in time are subject to experiment. There are experiment going on all the time, but that's possible to do it on a computer screen, but in reality, we're offering some consumer products, but for many engineering systems, it is not possible to conduct a little experiment. So often it's infeasible, but very often, there is variability that occur naturally in reality. Things are changing in reality, and you can collect data, and this data sometimes referred to as natural experiment, when the variable that captures the causes that you are interested change in some situations, if you can collect data on that situation, we can then make influence on cause and effect. It's more challenging, more difficult, but that's mostly what we are focusing in this class. But there is one other way of doing it, which is to do hypothetical tests, ask people to think, or use to think about potential situations that are different from reality, and tell us how they're going to this, how they're going to react. This is called state. I noticed that maybe I'm discriminating other people that are sitting on my right, not that I'm a leftist, but I'm pointing to one screen. Is this okay? Can you that it works? Yes, okay, sometimes I will go to your side. So, so these thought experiment situation where we create a hypothetical scenario of interest. So if you're interested to see how would people react to automated vehicles, how people will respond to automated vehicles, and we want to get the reaction, so we describe to them the service. We describe to them, what the vehicle to do, how much it will cost, what does it, how safe it is, etcetera. Provide information and ask people, How are you going to react? And as we call it, stated preferences, because we give people different options, and then the response, it's like, you know the difference between a real experiment will be, you go to a restaurant, you get the menu, and you may choose one menu and you eat it. Thought experiment will be able to send to your menu. I said, assume that you're going to the restaurant. What would you choose? And hopefully people will give us useful information. So there is always questionable external validity. It's very useful information, and we spent some lecture to talk about this kind of data, because it's used a lot. It's used a lot in many applications in marketing research. It is offered to us controlled analysis. We just call it choice experiment, but hypothetical or stated preferences choice experiment, then they already talked about the idea of machine learning on data driven models, those theory based models. So the idea is that data driven models are flexible. They when you have big data and a lot of data, you can base the specification entirely on data. The problem is that causality may be unidentified or biased. I mentioned that if you have data, they may not be the natural experiment to be sick or not in the data, although is high level of collinearity. And so causality may be unidentified or biased, and why it is biased, because sometimes there is in data, your variable, that suffer from what is known as endogeneity. I will not get into it now, but I'll talk about endogeneity, and that's because if you do have it, then the inference that you make, that you can make from natural data for real data will be biased. Bias, if you're interested to predict causality. Prediction may be counter intuitive, demand, alternative, monotonic in price. So using explosively data to even model. You may, you may get results that will be untrustworthy because they will not behave in the way that you expect it to behave. And so for demand and price, we expect demand to be done, but stopping getting the price increase, demand should decrease, but sometimes there will be issue in the way, in the data that will cause us to get ourselves in which prices increases, the money is increasing, and then the model cannot be used for analysis. So this contrasts with a theory based model. So what does it mean? Theory based model? It doesn't mean that there is no data. Data are critical, no matter what we do, but by specifying the model so that it agreeing with some employee theory or knowledge of what is considered to be transversing property of a model, and so that the idea is that the a priori assumption about how the model should be behaving and and the model that does not behave accordingly, according to this a priori expectation common sense can be rejected or will be rejected. So so for example, if there are in a theory based model, if there are confounding effects or measurement errors, things that cause bias or lack of identification, there are ways of treating it. There are ways of dealing with it, often using something called instrumental more later. So that's advantage. I mentioned that in the data driven model, sometimes causality may be unidentified or biased instrumental variable, methods that will be described can deal with it. So transplant prediction is a key for analysis. Is why some theory, theoretical basis is necessary when we combine it with data, and that will be the focus in this class. So I'm not teaching in this class all these algorithms that you may have come across already in a machine learning course, so that you will like logistic regression, support vector, decision trees, random phones, neural networks, all these algorithms I will not cover in this class. I talked about the principle of this method and how they may be applied to regression and to discretion, but I will not be teaching this algorithm. This algorithm rely on out of sample validation. Unique data is divided into data that is used to calibrate to estimate the model. Usually it's called training data, and then data that are hold out or not used in the first in the statistical influence are used to select between alternative models. And so out of sample validation, some determinant of the model selection you election when you have a lot of data in it, sometimes, often you require to use something called liberalization, which does introduce some violence into the model, but it has advantage in terms of producing billions more in later in connection for this ratio is analysis. We have also models that increase in sophistication. We will start with something called the logic model. Then we'll have a family of extension of logic called extreme value family. But the most commonly used model is nested loggies and another model called cross tested logic. And so this is the second kind of adding complexity or adding flexibility to the specification. Then very flexible way of dealing with discrete choice is using mixture and so I explained what mixture modeling is all about. And the most commonly used model being mixed is a logical logic mixture. Sometimes, so does mix logic. Sometimes. There are models with displayed mixture, continuous mixture. There is a model called probit, again, which is a flexible which is included in this class. So this is a very large class of discrete choice model that can be very complex and have many unknown parameters. And finally, there is a class of model that I will not cover in this class, that's in my other class called the hybrid choice model. That's when discrete choice model is combined with structural equation modeling, models the terms. So these models are used a lot with psychometric data, and so we want to combine them with discrete choice that's called the hypo choice model. So the idea of these models is that hypothesis hypothesis driven, and because a particular model specification is based on hypothesis of what are the effects that you're trying to measure, what you can expect to be and therefore interpretability is first, the model must be transformed. The parameters of the model must have in interpretation that agreeing with some theory of apoyo interpretation. So emphasis on identifying the causal effect and suddenly check against common sense. So that's sort of first of all the philosophy. So we are focusing in this class on application of classical statistical inference to models that can be used for analysis. That's kind of the summary in one sentence of the focus of this class. And to do that, you will first start on inertia, and that is great choice. Why? What's different in relation analysis, the deep and variable y is continuous and and then we have a specification that can be have a linear form of this nature, or can have some non linearity, some function g to be specified. The difference between here is that we just denote the unknown parameter with the Greek letter beta, and here we denote that this function g denoted the angle parameter is beta, is theta. The betas are often referred to as coefficients, but there is some variable, and the sensitivity of the response to this variable is measured by a coefficient. There's always a random effect. The W is epsilon, and sometimes the stochastic effect is more than an additive, oh, like the betas themselves can be treated as stochastic effects. It's called random coefficients, and the same applies to theta. So that's regression analysis when the dependent variable is discrete or categorical. So we have many situation for the dependent level. It's not even ordinary. It's not like 12345, it may be a different category, bus, Subway, or, you know, Uber lift or fold and Toyota. So you have categories and and that's why we apply this great choice. So now alternative, which is just a set of items that the user has to select among. And so we have like the alternative, or denoted as I, and the set may include J alternative, and we model the probability of choosing an alternative. So the dependent variable when you observe we observe a choice. We observe persons selecting so the y is one of these options that will select it, but the dependent variable of the model that will develop is predicted probability. Now the y is also random variable. Here it continues. It's a random variable that is distributed with this systematic function will be the mean of that variable, or the expected value of y given x to the z, and there is an additive epsilon. But as I said, it could be other stochastic effect in the spiritual, categorical dependent variable. The model predicts the probability. A special case will be deterministic. I'll show you in a moment. I'll show you so there is some function of again, the explanatory variable x, and some other parameter, theta, this model will always be non linear, because this probability is bounded between zero to one number that can be range from zero to One, and the excess could be continuous or discrete. And so this model is not linear, and

the modeling steps in any kind of COVID model begin with identification of people, and there's an independent some prior idea of what, what are we trying to predict, and what are the causes that are the independent variables, or what are the variables that affect the causal relationship? The next step is data collection. Sometimes the data is already available has been collected, data that is naturally collected from some transaction databases, for example. And then the next step is physical inference. The models always have these unknown parameters, and the question is, how to estimate values for these unknown parameters, and what are the properties of these estimates, how good they are, and then the model is applied to the analysis to predict what will happen if so, these are basic concepts. Next, I'll talk about a little bit about data. I already mentioned that we have data from reality people actually, if we have experimental data or we have natural data that contain a natural experiments and distinguish it from stated preferences, hypothetical scenario that they mentioned. And so their preferences is what people actually do users. I mean, the users wanted to be people. It could be an organization, a business establishment, and data on living preferences come, usually from surveys or from some sort of a customer database or transaction database that are naturally available in stated preferences data. We the analyst design choice experiment, we describe hypothetical situation in a survey, present them to the respondent, and we don't let the respondents just to have the days or months to make a decision. We need to accelerate the process, so it's done in the survey, so the information is presented in the video, picture or with a list of items, label, different format and information is provided, people make decisions, sometimes, in reality, to collect additional information, you can simulate this. So this idea is simulating, in some sort of a survey, how people make decisions, and observe the decision they make, where the setting, the options that are described are generated by an analyst. We observe the choices, and this is called stated reference data. So it's very useful set of data. It's used a lot in research and in the marketplace in many different ways, and we'll talk about it in the class. And I have an example. There's a company called Soto software that produce offers software to market researchers, and this is an example from their website. And so it's an example of a stated reference, what they call conjoined study. And so they tell the respondent, so it's hypothetical, just they picked it up to the website. Imagine you are an evening sports game, baseball game, if you've been to a baseball game, and so the game is more than halfway over. You're very hungry and decided to leave. You'll see to buy dinner. Which option would you choose? And you have here about six options of food and an option to say none. I will be not none of these. If that's not available, I will, I will not eat it later. And so in this case, assume that you select only one of these. Sometimes you can select it any assortment. It's a positive one, a salad and a pizza. It's also a possibility they don't. They present it as if you can have only one of them. And so first of all, there is a picture that describe what the alternative food is. And then there are some name label assigned to each of this alternative. And then there are some attributes that describe the option. So in order to buy this sandwich and sleep even in line, and if you take your postulate, it's before you get so, and you have to pay six and a half so same kind of information. And then you have to choose, it's hypothetical. You're not in a game. You may be in your office when somebody is asking you this question, but you can intercept people in the game and say, suppose, imagine now you're on the game. Shortly, in the Showtime, you will be hungry, and suppose that this was the option that will be available to you. Well, the options available to buy may be very different, and very often in this experiment, you do multiple experiments, you include those bonuses. Are you willing to participate in such a survey? Please respond to this experiment now think about the new situation. You're still in the same game, but maybe other kinds of foods or different prices or different waste time and etc, or different pictures and so just from this example, I made up an RP version. RP means on Fifth preferences. Suppose that I don't I don't want to make it hypothetical. I want to know what people actually ate during the game, so I wait outside the gate away somewhere, when people are leaving the game, and they ask them, or I call them or find them after the game, and they said, Well, ask me who you are, what's your age, and collect information about the respondent. We call this variable in describing discrete choice, in discrete choice, couples of this class. We will distinguish the independent variable level in the model. We have y, some deeper, the variable i, and then we have the independent variables x, the cos and we'll discuss the distinguish between two kinds of discrete choice, two kind of independent variables. One type are called attributes. Which are these things are called attributes. What you see are attributes. Some of them are pictorial, some of them are verbal, some of them are quantitative. Quantitative. Okay, so these are attributes, but when we conduct, when we study different individuals and people are different because of their age, because of their gender, because of their occupation, because of the income, they may make choices differently and have different preference. So we collect all this information about things called characteristics. Characteristics will be a variable that we may want to include in the model, not because they are causes necessarily, but because they explain the difference between individuals so and so we would include in a model characteristics. So like people might do, a different age, have different preferences. I was told not to eat too many hot dogs. Why? Because I have an advanced age, right? So be careful from eating too many of them, one hot dog per year every time I eat. Oh, I begin a new year. So today is you're asking the survey question about the person. Usually you ask this at the end of the survey. First you conduct the experiment, and the answer is, what did you do during the game? Did you eat anything? What did you eat? You can get a yeast you can check what you ate. And the bottom is that in such a daytime we then have to go by analysis, to go and say, Okay, what are the options that are available in this context, how much did each option cost, and what was the wait time? What are the calories different items? So the analyst needs to collect additional information. So this so called review preference data require more effort to collect. And so that's why, for a lot of research studies, people rely on stated references. But this data is very valuable because that's what people actually did, which is what you're trying to predict. So one of the topics that will go in class is not going to combine RP and SP and output. So discrete choice so what are discrete choice models? So first of all, the purpose of discrete choice is to, as I said, to predict

what RP will select from a set of options? And I told you that one possible selection from a set for the set of options will be to select an assortment. So we first define a choice set that will include all possible assortments. So if you say you can only select one food item, let me know what the choice that include all the alternative and the options of opting out. Not easy, but if you can select any assortment, then you can you're so hungry and that you're so thin that you can eat everything, maybe. So we have to list all the possible and then. So that's what we would call a choice set, all the possible outcome of the choice experiment and and so form a choice set, one in capital letter is because one and only one, meaning the new option is, I say I'm not going to select any is in the set, so therefore one and only one is selected. So we define the choices to be mutually exclusive, only one consulate and exhaustive, meaning there's always the possible outcome is in the set, and then we have so we have a choice set, we have a decision maker. The decision maker is faced with alternatives in the choice set, and the decision maker that bosses information to make a choice. And person can we can hypothesize different ways in which people make such decision. The decision maker, in many applications, would be an individual person, but it could be a household. It could be a business establishment of some some form. But, you know, discrete choice models where you have a categorical or discrete dependent variable, can you apply to other things that are not the choice? So, so there are applications, but everything that I will cover here is focused on application to choice, although the same with the progression does not, is not. It's not just a demand model can be a supply model. Can be other type of model, and the same thing is good for the school choice, but we focus on choice, okay? So, so we have a decision maker, and we can have some data about the decision maker, like education, income. Why? Because you may have a sample of decision maker, and you want to segment them to see how give people different decision makers, making decisions differently, like if you collect information about films, big films, small terms, different kind of films, etc. The alternative is a joy set. And alternative are described by attributes. So characteristic described decision making. Attribute decision so the whole kind of possible protocol that people go so when they processing such data and making a decision, the one that we're going to follow is idea of creativity, and we'll be able to estimate utility functions that capture how people connect playoffs between these attributes. You want to understand how people react with rating and if we think that we want to find out, if people say no wait and therefore go away, don't eat, it's not important. Okay, so. But there are also other numbers, like the dominance is important, because if you see that there are alternatives in which one alternative that's the best value for every possible attitude, we call it a dominant sometimes, but then we have to take into account possibility that maybe we got the data on all the attributes, then even seems like dominant can be controversial. So the utility maximization is the approach that we use most often, and because we can use it to sometimes, maybe as an approximation of how people make titles. And so the choices, should they eat? The pizza or salad? Two alternatives. The soon they get an individual person enters the context. Of course, maybe a Facebook game. And so the alternative is only two items, pizza and salad, the avenues, cost, wait time, calories in the decision, but our other attributes, this was the attribute that were listed here. But the picture is also an attribute. And the name is an attribute, because it's our names, our labels are also attribute. I call it the pizza, but, you know, you can call it, I don't know, call it another name, but pizza is an established name that has some it's like a brand that, you know, it's a kind of food that you've tried before, that you may be familiar with. So, so these are every single information. Here are attributes and the decision rule, if you assume that those utility functions or utility maximization with that's the purpose of the analysis now is to find out the modeling is to estimate what this utility is. So if you can quantify the utility for pizza, then we can predict that if the utility of pizza is less than utility of salad, then the person is predicted to use pizza. And or if the utility of pizza is less than utility and so the utility is therefore function of decision maker characteristics and attributes. Why attributes is clear. This of the causes characteristics, because people may behave differently, and if I can sample a very different individual, I want, I want to my model to be able to also tell me which how these characteristics affect the choice. So each of this utility would want to quantify the function, mostly of the key attributes and then but the taste parameters, which are the coefficient of this attribute. If you have a linear utility function, we can have a utility function which is linear in some variables, and then the parameters will call them coefficients, like beta. It's not regression, because utility is unknown. So it's not like this is not the dependent variable. The dependent variable is the choice, and and, this is an example of how characteristic income affects such a moment. This is just an example. It says that the effect, the reaction to cause, depends on income, inverse the proportion of the income. The greater your income, the less sensitive is the torso through cost focus. Course, but so this is just an hypothesized utility function. One can specify many different utility functions. The purpose of the statistical analysis is not just to estimate data, but sometimes to select about different potential specification of this utility function. So if the utility function are well specified, we can have a deterministic choice. It's so well specified, let's just see if the difference between the utility is only on this in the middle. If it's called an ordinary utility, if your salad is greater than you pixel, and this difference is positive, and then the choice is probability one is solid. If the difference is negative, then the probability of solid is zero. So that's a deterministic choice. This utility functions are not perfect, and so we use a model called the random utility model as a way of interpreting a model of choice data. We're saying that the utility function that we can specify based on the attributes that we have quantified and based on our understanding on how the utilities are specified, is represented by V, and it's incomplete. There is also some stochastic effect, random utility. So the V is a function of observable variable, but the random utility is unobserved. It's random. And so every time we write the utility, we have to have this stochastic effect. And so we write the utility of fraternity by for decision maker. N is the sum of the systematic utility fraternity by for decision maker plus the line of utility. Systematic utility is just a name. We call it because we don't want because the mean of epsilon may not be zero. If the mean of epsilon is zero, then the mean of the utility will be V, expected values. Utility will be V. To make it more general, we also do it as a systematic utility, and that's

so what's in the epsilon? Why do we always have this excellence? Because we may have attributes that we did not include, sensitive to sodium or to salt, or maybe you want to know other things about the food item before you select it. It affects your choice. You will make an assumption on it, maybe. So this, I observe that of you, we included income, for example, but there may be other characteristics that explain differences in how people make such decisions. So therefore there is always how the devil and the analyst specified suffer from all kinds of limitations. So there's always random effect that the things that we do not observe. And therefore we can only predict the probability. Instead of predicting deterministic choice, we can predict the probability of an alternative. And so if we have two alternatives, we call the model binary or binomial. So the probability of choosing salad from beside salad. So we write it is a probability of choosing salad given conditional on a choice that include pizza and salads, etc.

And it's a probability that utility of salad, because this utility is a random variable, then if you know the distribution of this utility, we need to calculate,

we can calculate this probability. So knowing the distribution of utilities, and if utility is equal to v plus epsilon, we if we make assumption about the distribution of epsilon, given these which are the mean values of the distribution will be able to then calculate the probabilities. And that's what this ritualist modeling is all about, how to calculate these probabilities. And the model that I told you about before, Angie, nestedology mixture, are all different ways increasing sophistication of way of calculating such choice probability. So this is just for two alternative, if we have more than two alternative, and then the probability of choosing i given some set of options C, the choice set is the probability that u i is greater than u j for all the element j in the choice. To calculate this, we need to know the joint probability distribution of all the epsilon of alternative in the choice. And the choices can be large,

convention wisdom says that these choice models can be applied only to small choices, small number of fertility. That's not true, and maybe the single people cannot make a choice for more a handful or maybe just a little bit more than a handful of faculty. That's awesome. Who has been who has not been to Starbucks? You've never been to Starbucks? I have a question. Unfortunately, I've been to Starbucks. So let me just finish the Starbucks. So somebody actually calculated, there have been articles about it, I think in the New York Times, that every time you go to Starbucks, you make a choice, you just have coffee. Maybe you just have coffee with 1000s and 1000s of options. You look at the different types of coffee, the different sizes, the different types of different way of making the coffee you're choosing, among some we calculated hundreds of 1000s of options of possible outcome when you go to Starbucks. So, so you can make choices, we can make choices about non fertility.

I have two questions. And one is about travel survey data and where that kind of sits in all these models that you've kind of spoken about. That's the first question. The second question is, you said that these are shoes only work for small numbers of choices. And

basically,

no, yeah, like, no, that that's not necessarily the case. But is there like, an upper limit that you have seen in the work, or is it that people are batching things and putting them into categories and then that's how they make the first choice, and then it's like, actually, multi level. I

don't know. What do you doing? I just picked something

that was familiar to

me, familiar to you. Yes, you remember the first time you went to Starbucks. Yes, it was not familiar to you at that time. It

was familiar to someone else. I found this.

But Did someone else make a choice? Right? And then advise you on their taste. And so I like you that doesn't taste your soil taste, and you selected the same. And so that's an old decision, but somebody at some point evaluated on the options. And so the outcome when I observe you going to Starbucks and suppose that I don't know you, I don't know all your friends, I don't know what coffee before I want to predict what coffee you're going to select in Starbucks, you're about to make a choice for 300,000 possible outcome. If I want to predict what you will do, I'll have to rejoice it with 300,000 possible options. So can we do that? Yes. Do you need a computer? Yes, you need a lot of data. Of course, yes, but there is nothing conceptually in what I'm going to teach you here that has a limit. It has to be finite. Yeah, has to be countable, but, but so sometimes I'll get into that, and you can deal with infinite options, but that's called continuous choice. But I will not talk about it like that. So in general, when I say choice set, we don't impose any limit on the size of the choice. Now you can say, well, if you want to show people different food items, like six or seven, showing one side by side. But when you go to a restaurant, especially, think about Chinese restaurant.

Have you been to a Chinese restaurant? Have you seen a Chinese menu in a Chinese restaurant? How many meals you can restart for a Chinese menu? You've all done it

like we've all done it so, so people make choices from the Philadelphia choices, and therefore the analytical method that I'm going to teach you should be capable of dealing with a loud choice. Now it's possible to think about choice as consisting of two stages. Stage One construct the choices, using some realistics, asking my friends, you know, just thinking about things that I've done in the past, or seek some information, but not full information, yeah, let me find the love good enough coffees that I am going to conceal today. And so you can apply holistic to come up with a small choice, and then you look at the price, and maybe I feel like today and make a choice modeling and using utility maximization. So utility maximization is a very good technique to capture. As I said, trade off is a trade off between some coffee price is very high, I don't know. Then you concur, if you know how much you like this coffee, and this is what goes into this utility function. So no limit on the level functions. Once we agree that the utilities are on the variable, then the choice, instead of becoming the step function, becomes becomes a continuous, monotonic function. We assume that this utility, systematic utility, indicate some strings of preferences, but, but it's, it's now a monotonic function as a different thing to it basically, weekly one, sometimes you can reach the asymptote, sometimes not, depending on the application. So that's it. That's kind of a quick introduction to the course. I still have time available. So excited about the reading, about the screen choice, I've written a textbook in 1985 it's available in quality, so it will be available to you. But there is a group of us that been working on the rising updating this book for the last 20 years and but we make chapters, new chapters from available to you as well, and that's another like a paper for application to transportation. The examples in this book is also transportation in the new book, hopefully there'll be examples and so on, not only for transportation. So there's a lot of reading on this great choice that will make available to you. We'll get back to it later in the semester. Next on our agenda is a review of probability and statistics. If you need to do the review yourself with the material I'm going to cover all the constant that I'm going to use later, I will mention, but I'm also counting on you having taken some course in statistics before, so that You know what's a normal distribution.

Maybe I don't know. I mean, take a look at some bleeding material. So I think also the lecture. And first of all, probability, and then statistics, and you find out what you may want to do some bleeding on your to refresh your knowledge. Any questions, if anything, about the course, about anything that you said today, still 1015, minutes,

thinking about when you have, like a very large set like she was describing, this is also robust to a situation where the choice set is diminishing over time, because it's a limited choice that like, let's say there's only five, keeps us available. So after five people choose, the sixth person doesn't have that option anymore. Are there models?

Anytime you predict the outcome, you have to take into account the supply. So you cannot just have the demand model. So we are teaching in this class how to model the demand, but when you apply supply choices, so if you're modeling our review processes, actual market in which the change over time, and you want to predict that the last change over time, you have to take it so I mean, suppose that you want mushroom pizza, and you've come and there's no mushroom pizza. Of course, you may decide, I want to have mushroom pizza, not eating pizza. So you have to model, it's like a separate model. Yeah, you have to model the supply, the choices. So as I said, it's always good to think about where does the choices come from? So this like choice of generation. So choice of generation include the supply center. Choice of generation can be an individual seeking information or creating a choice, but it could also be somebody else, like the establishment, that decides what's available. So, you know, we need, when we talk about choice modeling, we have a statistical model. There's the deep end available, which is a categorical outcome from this list of items, where this list of item comes from, Any other question,

any questions, yes, I

asked about so. I asked about the example. So you mentioned the name of food, right? Green, Father or pizza be the attorney about how to use how to use them.

Because I think only the

numerical value, but the value. So every time you have a category, so if I compare different cows, one car is made by another car. Another car is made by Volkswagen. So the brand name, in this case, will become a dummy variables describing food, the word pizza, there'll be a dummy variable one, if so, you have utility function, utility of pizza. You include the dummy variable, one is pizza zero, otherwise, there'll be another, say one if salad, or maybe green salad zero, otherwise, and there'll be a coefficient to this dummy variable. So every time you have on the right hand side, right if you have a model which is y as a function of x, x could be dummy variables categorical levels, if you have multiple categories, you have A dummy variable for each possible category. So that's the explanatory variable. Often, like, often, product and services as like, feature, like, is it a pizza or not? That is a bus air conditioned or not? You know, is, is a computer Apple or not? So on the on the left hand side, the deep learning can be continuous or critical. Same for the axis can be continuous on the goal.

Wake up. So

will we be talking about latent, like latent demanded, like latent choices in any of these? Because I think you mentioned it's only applicable to the hybrid latent

means unobserved. So what unobserved Are you interested in latent demand? Sorry, yeah, I've been interested

in modern day access to

like nighttime leisure, nighttime leisure, those

specific temporal and the purpose, and many times I've heard from but just anecdotally, I don't know how to get there. There's no transit option. If there was, I would go. So something like that. Would that be like stated preference

instead just transit, yes, right. So movies that are shown are terrible. You also will not go. So, of course, the demand, there is an observed demand, but there is a demand possibilities. I mean, demand can be very loud and very small, so there's always latent. So some I can observe demand at a certain range, in some range, I cannot observe it so late in the world. The word latent demand is used in transportation, but it's kind of not very clear what it means, because some demand is latent. I mean demand. That's what we're trying to estimate. We are always trying to estimate what will be the month if the condition change is the supply chain, is the entertainment opportunities change if there was transit available, right? So, so, yeah, it's interesting to know. I mean, if I'm like an entertainment area and it says, you know, what would be the demand for people visiting this area, if public transportation to that area would be poor? That's a standard demand question. To call it latent demand. No, it's a demand. We want to ask him, What would be the demand if we change the accessibility of the location?

Will that be touched upon in this course?

Is about this problem so specifically is the entertainment area, the demand is the people choice to go and visit this area, so they have options. They can say, Oh, watch TV. They can go to another area, or they can so they make decisions. And the decision to go to a particular location, to a given location, will depend on the offering and dislocation, the cost of entertainment, location and opportunity, that way of accessibility, of getting them, etc. So these are the attributes, but they just a standard demand question. And I know that the discussion about transportation. A lot of people, people tend to talk about latent demand, unrealized demand, that you know because there is a demand, but we don't see it because there is no good service, of course. I mean, it's always told about demand. So to Adelaide, latent is not a good idea. It's kind of confusing. Yes,

are there certain industries where, like you, have tighter prediction bounds, just by nature, for example, transportation versus consumer goods, which cereal do you choose versus which transportation mode do you choose? Is there any kind of high level trends across industries,

in terms of trends, in terms of ability to predict our ability to predict demand depends on the volume depends on the data and then the level of information that we have about the attributes and people characteristic so, so it does not depend on the product, but depends more on what information you have. So if you have, if you have a consumer database, transaction data, where you know very little about the consumer that's very difficult to predict. But if you are Amazon, Google, and they know everything listen about you, they can predict much better what you're going to do. And so we'll talk about later this semester, but also online application of choice. So the focus of this, course, but I will talk about, but that's clearly a good example where we have a lot of historical data, and, you know, and we can, they can do a pretty good job in predicting what you do, whereas you have, like, a some sort of transaction database when you know very little about the consumers, that is very difficult to predict. A lot of the more, a lot of the research for these techniques are being used. Focus not so much on projection of what you what the weather you buy or not buy, but more. How do you deliver different attributes? What? What is your How do you value public transport, accessibility to an entertainment location, versus the offering in that location? What's more important? How important really? Relatively. I mean, it's all relative. Is public transportation service, for example, anything else? Maybe I spoke

too fast. Did I speak too fast? Okay, so

and Hi everyone. I'm excited for this class.

