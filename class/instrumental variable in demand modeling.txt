Speaker 1  
Is he taking proposal this semester? Sounds like

Unknown Speaker  
it's too far in

Speaker 2  
the afternoon. I also have

Unknown Speaker  
motion for my common person, hopefully,

Speaker 2  
transportation, I'm in transportation, believe it or not. So that's our, my kind of, my and Charlie's plan to make that as kind of a establish field in transportation, because mobility venture generalized,

Speaker 2  
relevant information appreciated. Pass it over here. Mobility venture,

Speaker 3  
from it to the Okay, so today is a beginning. It's an important topic, so I take my time, and if I need more time, I'll come back to it. So don't hesitate to ask me questions. And so I'm trying to not to get into so the plan for this lecture, part one, review of Gauss Margaux assumption is for you, I'm reviewing. You can review it yourself. It's in the slide, and I spend, as you know, today, the topic is the violation of the exogeneity assumption. And so if you, if exogenated is violated, we have a case of endogeneity. So the name of it, the problem is, endogeneity. Endogeneity. We need to address it. And so I spent a fair amount of time on examples, five different examples, on the causes of another or five different sorts of maybe examples, but examples of situations in which we are generating, in Which this assumption is violated. And you know, if this assumption is violated, then the estimates, the estimated parameters, are biased and inconsistent. And so given that we are looking for models where we can identify the effects of specific variables, decision variables. And as you know, unbiasedness or consistency is the most important photo people. We just finished talking about violation of the spherical error assumption and they told you have a lot of data, this assumption is violated. Okay, it's not so bad, and we don't necessarily have to recover from it. And we talked about, sometimes, the approach of generalized weak. But now we are talking about the problem that we have to deal with. There is no way wave our hand and say it's not important. It's on the efficiency we have to deal with it, because when it occurs, you get incorrect, inconsistent, it's wrong sign. You cannot use the model for analysis. So when you encounter one of these situations or others. When there is endogeneity, you have to deal with it. And the way to deal with it is to use instrumental variables. So first I'm saying talk about situations in which there is endogeneity, then to deal with it, to address it, which we have to do. We need to find instrumental variables. And I know that there's some techniques. The technique is just like Russian. So the difficult part of this lecture is to know that you have a problem, like to detect the deal important, and to then to find the instruments. So once you find instruments, then the methods of regulatory and in this case, in the last case, it's called two stage least squares. So I'll basically show you this will be the technique that I would say you should apply when you have such a situation. So again, the difficult part is to know when to suspect was to suspect imogeneity and and then it was so you remember, the assumption that is being violated is the assumption that the expected value of epsilon given x is equal to zero. All that x and epsilon are uncorrelated. That's a weaker assumption. And then, and so if you think you can take the residuals and calculate the correlation between the residuals and x, and that will tell you that you're not related. You are badly, badly or because, if you try to do the text and residuals, are they correlated with X, they're not. They're orthogonal to x, and if they're not orthogonal, then the least square was not calculated properly. So by definition, the mathematical property of v square. And sometimes you can, you can see, but this square is the technique that you used to need to use in order to obtain orthogonal residuals. So if you take the residuals and multiplying by any column of x, including the column of ones, for the intercept, it will be exactly zero. That's the first order condition of the mean square of calculating the V square estimator. So, so therefore it's not like in the case of the spherical error assumption. I said, Okay, you can start with ordinary squares and get consistent residuals and look at the residual those cattle plot. You cannot do it here. There is no, I mean, looking at the decision saying how they could correlated, is absolutely you have. So this is what it's very important to know. Well, one way of finding out is estimate the model, and you get 2000 don't make sense. You know, based on your domain knowledge, that parameters do not think of the right values, but usually you get all signs. And so that's way you find out, the hard way. But if you know that, if you are in a situation like the one I described, then you have to suspect endogeneity. And then in order to find out what was the effect of endogeneity, you have to deal with it. You have to find instruments. So you have to suspect that you may have endogeneity based on the results that you get, if you just apply ordinarily squares, you may get results set down, the model is clearly not usable, and that's one all you you have good things, and best of your knowledge to suspect that the situation, that the kind that I would describe, exists, and then you have to go and deal with it and see What's the difference, it may not make a big difference. So the key is to find this, to suspect that the underground gene find instruments, and then apply this instrumental variable regression that I've described here. Okay, so as I said, I will skip this. The key is that this assumption is violated. We get inconsistent estimates. You have to deal with it. The consequence essentially makes the model not usable. You have to deal with it. Okay? No situations. It is just repeat. This is the assumption. We call it assumption two, some sort of orthogonality of independence, whether the strong exogeneity, assumption that the weaker was correlation or covariance, and without assumption to be endogeneity. And I'm now going to describe this situation where ordinary s squared would be biased and inconsistent. So first situation is omitted values, very common situations, and you want to estimate the model you have a relationship that they have in mind, but for some reason, and one of the variables in this example we will see actually, so suppose that for some reason, X ray is unavailable.

Speaker 3  
Oh, you may have, by mistake, taking it out. Maybe you wanted to deal with multi COVID, you estimate you want a regression without x3 that's n so x3 belong in the model. After you will believe that it should be in the model that vector three is not zero, yet we estimate a model without beta three. That's an admitted variable situation. So when we estimate this model, it means that, if this is a true model, it means that the new epsilon, epsilon tilde, includes these two, the original epsilon, and this term, and we call it epsilon tilde.

Unknown Speaker  
Now this epsilon tilde will be correlated with x2 if x2 and x3 are correlated. So if you have multiple linearity, and you take one variable out endogeneity immediately,

Speaker 3  
because, I mean, if you take x3 because it's correlated with x2 then you have an omitted variable, the epsilon is correlated with the remaining variable. And the estimation in this model, you don't get the two estimate of the two effect of x2 Oh, where x1 zero is biased, inconsistent. So therefore, I told you it's not a solution for multicollinearity. When can you omit a variable, when beta three is practically zero, and you believe that, if you strongly believe that the variable is not model, but you can test it, you can estimate this model and test wait to sleep, but for some reason, it's not available. You know, it should be in the model, but it's unavailable. And a typical example, as I mentioned, I'll use, is, if it is a demand model, you usually have some variables that measures the cost of the price. When you want to use this alternative, and sometimes describe the quality of the alternative. So usually it's some trade off between some measure of quality and price. And if you don't have a good measure of quality, you don't need it available and and so you estimate this model, and you know there should be equality variable, then you have an amazing variable program. And, and usually what will happen is the estimation of the price effect will be way up, very long. P.

Speaker 3  
So, so sorry about that. And so that's that's the situation where the correlation between epsilon, head and x is clearly not zero, unless x2 and x3 are uncorrelated.

Speaker 3  
So if x3 is orthogonal to x1 and x2 if it is orthogonal to exactly orthodont then beta one and beta two will be unchanged. That's kind of nice, but it doesn't happen. It's always correlated. So as long as beta three is not zero and usually some correlation, then it depends on the degree of correlation. And so this might be a weak endogeneity or strong endogeneity, and but usually, if you know that there is a variable that should be in the model, it is omitted, and there is no reason to believe that it's not correlated with include. It's usually, you know, price, the quality, are usually positively. So that's so in this case, we say, when we estimate this model, that's about the time to estimate. We say x2 is endogenous. Why? Because x2 and the L term are correlated. That's the definition of endogeneity. We have variables for some reason correlated with the algorithm. And this is an example of the correlation of girls, because we have an Omitted Variable situation.

Speaker 4  
So in summary, if x3 is not related to x1 and x2 that's mean orthogonal. In that scenario, there is no indigenity, okay, if correlation, and

Speaker 4  
if there is a correlation with weak correlation with one variable, then weakening and so if x3 is weakly correlated with x2 then with endogeneity, there will be and if there is high correlation, then high indigeneity, yeah.

Speaker 3  
So if this covariance, you know, maybe really close to zero, maybe very high. I be really high. This

Speaker 5  
is, is this a reasonable method to determine whether there are variables that explain the relationships in your model that you're not measuring like maybe because you don't understand the domain well enough? Is, is that a reasonable application of this? Or would you only, should you only consider including variables because of this, because of correlation with the error term, if it's something that you know should be in the model, which I'm a little

Speaker 3  
bit confused by, I put emphasis on the No.

Speaker 5  
How do you know, like, especially if you're I mean, sometimes it's obvious, but like, if you're modeling something complex, then there may be variables that you don't know, and I guess in multiple things, because if you know it should be in the model, then why are you taking it out of the

Speaker 3  
model that you don't include that you know, known, unknown, yeah. So you have to know that an effect is not in the model that should be in the modern so you have to evaporate your hypothesis that X ray should be in the model, and it's not in the model for some reason, and it's likely to be correlated with external for you, you're going to get biased estimates. Okay, so

Speaker 5  
just one follow up, like, what if I have a model and I've put in, you know, I have five explanatory variables that I think describe the relationship. But then, you know, I run the model with OLS, and I find that the error term is correlated with at least one of my X variables. You

Speaker 3  
cannot find it on because I just said in the beginning, if you take the situation, okay, it would be orthogonal to any X in the model.

Unknown Speaker  
Okay, so what is the error term here?

Speaker 3  
Then how would I measure that I said you cannot, okay, meaning you cannot begin by saying, or less get the residual and then do some calculation and decide oh, meaning I cannot estimate this volume, calculate epsilon tide hat, once I substitute in this equation for the beta two, beta one, beta two, the beta hat. And I calculate the residual. We put the head on it, right. That's the residual, correct. So if I run all this in this equation, I get residuals, which we in our notation, we call it epsilon, theta hat. And then I said, Okay, you're saying that x2 is endogenous. Let me calculate the correlation of the covariance of x2 and epsilon tilde hat, and it's going to be exactly zero, because the rounding of it may be point 000001, 00001,

Speaker 3  
so you cannot, you cannot check, you cannot test the assumption. But you look at the or less results out of this model, look at beta two, and it may have sign, or it may have parameter, the value which is too high or too small. Maybe this is price, and it looks like it's insensitive to price or overly sensitive, and and then you have to use your knowledge and says, yeah, what is another endogeneity problem here? And say, let's look at the one and say, Oh, I forgot to include an important effect, x3 and if you include x3 you'll get different results, different parameter. So, so if you estimate this model, you have no problem. Because of this model, all the assumptions are okay. Of this assumption, the problem is that this is a correct model, or the two model, and you try to estimate, you omit the value that should be in the model

Speaker 5  
for the symptom that's observable is, is a incorrect

Unknown Speaker  
observable,

Speaker 5  
right? But this, the problem that we observe to on this topic, is incorrect signs. That's because, yeah, we

Speaker 3  
see that same coefficient that we estimate seems to be wrong, gotcha. And then you have to use right.

Angie.H Moon  
There's a saying that we are the prisoners of our perception. And so I think kind of the second model is, within that model, there is no way to self correct. You need to know kind of a bigger kind of information, right. You need to know

Speaker 3  
the reason that there is a possibility of endogeneity, because my model is more specified, the important effect is missing. Okay, so that's Omitted Variable. Situation very common. Next is measurement like I tell you, I can give you an example that I've been involved in for airline the research team trying to estimate the model of fact you can make a choice between different itineraries. Flight attendants. You know, when you go to book your flight, you have options available to make a choice, so they model this choice and twice the COVID resolve because of another because of endogeneity. That's an example, and they had to collect for endogeneity in order to get the effect of price to be to be collected. Okay? Next situation. Measurement also happens frequently. If you remember we talked about sprp data, is primarily in effect with the R P data. So suppose that gives the two model again, the same as before, the two model, but now we don't have X ray, but we have an imperfect measurement of X ray, like somebody invented some measure of quality that we're using some engineering estimate instead of observing an accurate measure of quality, use of approximation. So we write here assume that the L is random, so x3 is four variable, but we have x3 star, and the difference between them is some noise, say, random noise, no, nothing, no bias, or anything like that. Just so this is refer to as a measurement assumption, measurement model. And this means just under measurement, simple measurement. So suppose therefore that what we have, we have available this x star and so on. This is a tau relationship. You mean, try to estimate the total relationship, but we use the X star instead of x because we don't have X. In that case, the difference between x and x star, this difference multiplied by the parameter vector three, goes into the L term. So the L term before was epsilon n, and now we have epsilon called epsilon star that includes the original epsilon as say all the assumptions are correct for that one, but this one would be correlated with x, so it would be correlated with X ray, because now x ray is in the algorithm. And I'm sorry we would be correlated with X ray star, because you see x3 star is in now in the algorithm. So as long as beta is as long as this difference is significant and beta three is not zero, there will be a correlation. And actually the correlation depends on the value of x3 it is the covariance. The covariance depends on the value of x compared to three and on the variance of this error term. So if the measurement error is large, then this covariance will be larger. So that's so we have endogeneity, and the degree of endogeneity will be depending on the measurement L. So if you think about measurement l bonding, we can have measurement L in the x's. We can have measurement L in the Y. Measurement L in the y is not the problem, because it just goes into the epsilon. That's not an issue. The issue if you have measurement L in the independent or explanatory variable like here. So the example is we have one variable x3 that we measure with L as a consequence and the effect of endogeneity in this case is usually observed by not necessarily wrong sign. Sometimes it could be wrong sign, but usually it's what's called shrinkage. The coefficients shrink towards zero. So if it's positive, it becomes less positive. If it's negative, it becomes less negative. So I mean, it's actually intuitive, because if you have a variable that is not measured well, then it's difficult to capture the effect of that variable, and it kind of moves towards zero. So that's the bias in this particular case. So that's the situation. Measure metal. How do you know you have it? Find out that maybe variable that is should be in the model comes out repeatedly, is insignificant, and you wonder why I know this should be there. The fact should be there, it seems to be insignificant, maybe because the gentleman was measured as well. And so, like in transportation models, if, if you calculate the total time based on screen measurements. And you're trying to find out what the effect of total time, and it comes out to be not very significant. It may be because total time was not was measured with zero. So that's measurement. Next is question, Brian, so you

Speaker 6  
said, variance without

Unknown Speaker  
a bias. So,

Speaker 3  
yeah, I made assumption in this, that the measurement model is this. It could be more complicated. So this is a measurement assumption. So I see this. I assume the very simple measurement assumption. Simply measurement model. Is it more likely,

Unknown Speaker  
in reality, that, like you have a system? Systematic measurement error.

Speaker 3  
I don't know you. You should know your measurements. I should know mine. I mean, I know, I don't know. I mean depends. I mean, depends on the situation. Yeah, you can have a bias. You can tend to underestimate double time or overestimate.

Speaker 3  
Underestimate the double time of the alternative on the model they use and overestimate the travel time on the model they do not use. Yes,

Speaker 2  
could you explain the examples? Again, the travel time here? I didn't

Speaker 3  
understand. Suppose that you estimate the travel time in the model, and they didn't hear from travel time, you calculated it. Rely on Google speed. You calculate the travel time, and now you want a regression and variable. It's an Angie calculated travel time variable based on some assumptions. Okay, yeah, so that's and that's maybe, you know an equation that describes the fact that your calculations are imperfect. Okay, next is alternating, so you're modern, and you have, before we go to the this particular example, you have a regressor. That's meaning one of the x's, and that is determined together with y, some you know, things that affect the vessel also affect y. If you can see the two equations, you have y1 and you have one of the variable in the in this model, let's just focus on this equation. One of the variable y2 is correlated with epsilon one. Why? Because y y2 is also determined in the same process, the same process that leads to y1 and maybe the determination of y2 is an equation that looks like this. Maybe we are not interested in this equation, but there is another equation, another process, in which y2 is determined either by y1 itself or by an epsilon two that is correlated with epsilon one. Usually the case is the subunit is y2 is also a function of y1 so epsilon two or y1 affect y2 epsilon one affects y1 and therefore epsilon one and y2 I'll call it this. So if these gammas are not zero, then epsilon one affect y1 and y1 affect y2 therefore epsilon one and y2 are correlated. And if I just wanted, if I say I'm only interested in this equation, this equation I know about, but this is equation that I'm trying to address, meaning I have one variable in my model that is determined simultaneously, meaning there is another equation out there. And so the common example for that simultaneity is a demand and supply. So I'll get equilibrium, because demand function, suppose that is a demand function, this is quantity of the function of twice, and this is a supply function, which is twice as a function of demand. And so I will come back to this example at the end of the lecture and say a few words about this particular example. But it's endogeneity. So you can see in epsilon, one and one two are correlated. So we have, again, we identified the variable in the previous example, it was this x3 we say x3 is endogenous. Now here we have an equation, and we have a variable. Maybe this y2 is twice the very important variable and and we say it's endogenous. So that's simulating an example is simultaneous equation, and so we may or may not sometimes go to estimate all the equations, but let's assume that we're just instrument as an instant in demand, but we know there is supply, and we know that the observation that we observe, observation in which the model supply dropped. Okay, next example is time series. This is what they talked about last time. So this is actually an example that they already mentioned to you. And we had a model that looks like that. We had a large dependent variable. So this was on a slide last time, and they said, when the approach they described you last time, you cannot apply because you cannot start with OLS. Why can't we start in with all of because if these epsilons are correlated over time, for example, a, r1 so if the epsilon t is correlated with epsilon t minus one, meaning this flow is not zero, then Y t minus one and epsilon t are correlated. Why are they correlated? Because epsilon t is equal to this right towards the epsilon t minus one dt, and clearly Y t minus one, there is an equation like this for y t minus one is a function of Y t minus two, but it has epsilon t minus one. But epsilon t minus one therefore is clearly correlated with with Y t minus one. So Y t minus one and this epsilon t are correlated so, so when you have a situation like this, when you have a non dependent variable, and you have serial correlation, auto correlation, even as simple as a one, then this Y t minus one is endogenous, and applying or less, they give you bias and inconsistent estimates. And therefore, if you apply OLS to this equation, you get residual estimates. Remember that point I described last time at the end was, you know, another OLS gets a residual and then determine what oil is. You cannot do it because OLS give you residuals which are not correct, which are biased, inconsistent. So you cannot proceed. Cannot start with OLS. So what do you what will really do? You start first by dealing with endogeneity, then getting consistent residuals and then proceed as last time. But you have first to deal with endogeneity, and we'll talk about it. We have to find instruments. Yes, go ahead. What exactly do you mean by consistent Yes, a consistent estimate means, I defined it meaning that the sampling distribution collapse in the two value

Speaker 2  
without samples, I Think, asked, what is consistent residue, not consistent estimator.

Speaker 3  
Consistent estimator, you calculate residual, which I call consistent we are estimating the betas. We want to get consistent estimates of the beta. Once we have consistent estimates of the beta, then we can calculate residuals which are consistent data. Because there's consistent data, I would have consistent procedure if I had bias data, I get residuals which are biased, and I cannot reach conclusions about auto correlation based on residuals which are inconsistent. Yes for the

Speaker 6  
case three simultaneity, yeah. Is there a solution to solve for the endogeneity?

Unknown Speaker  
There may be. You have to wait for the end of the

Speaker 3  
lecture. The solution is x1 and x2 have to be different.

Angie.H Moon  
Okay? I'm a little confused. Sorry, I thought the endogeneity might be more relevant with the unbiased estimator rather than consistency, because here we are dealing with expectation of epsilon given x equals zero. So I'm curious like, why you mentioned consistency of the estimator rather than unbiasedness, just now,

Unknown Speaker  
because unbiasedness is a storm problem, so it means that expected value of data head consistency means that the probability limit is equal to beta, not the expected value, but the probability. That's the definition of consistency. So it's a real property.

Speaker 3  
We prefer unbiased but in order to get unbiased estimates for this. If strict exogeneity is applied and is assumed, or under, under strict exogeneity expected by if epsilon given x equal to zero, we get a greater head to be unbiased if we don't have strict exogeneity, but we have the property that the probability limits of x prime epsilon divided by n probability limit equal to zero, which means that x and epsilon are uncorrelated. So if you have a very large sample, and you calculate the correlation of x and epsilon where you cannot calculate its assumption that in the large sample, x and epsilon will be uncorrelated. So the expected value of epsilon given x usually means the two are independent, independently distributed. The peeling condition means that they are uncorrelated. They may be dependent, but they're uncorrelated. So just a weaker assumption. So we replace the assumption that the expected value of epsilon given x equal to zero with an assumption that the probability limit of x, prime epsilon divided by n, meaning that the correlation of a correlation

Angie.H Moon  
of zero. So can I understand that as even we cannot achieve some strict exogeneity By targeting for consistent estimator, we can avoid the endogeneity. Kind of

Speaker 3  
avoid saying making an assumption about the absolute so we have two possible assumptions. One assumption is strict exogeneity, a weaker exogeneity, assumption is weaker, strict Illinois exogene And then we have endogeneity, okay? And if you have, if you, if you have strict exogeneity, you get unbiasedness. If you have the weak exogeneity, you get consistency, only consistent biasness. And if you have ill Genet, that's very

Unknown Speaker  
helpful. Thank you. I

Speaker 3  
just have to find it okay. So we cover time series. So when you have line deep and available, and autocorrelation, you will endogeneity, you have to do something about it. In all these situations, we will have to find the instruments right. And so remember this situation, we talk about them. When we talk about instruments, we can talk about what will be the instrument under width is very well. It's very difficult to find in measurement, though. We'll also have to find instruments in Angie in simultaneous situation, the instrument will be something that will be x2 so if you have simultaneous equation, and you know what x2 is in the time series, The instrument will be for y t will be X t minus one will be The instrument. So explain instrument. So there will be some situation will be instrumental kind of formula, but we're coming through. Next is self selection. What means self selection is that the people, entities now modeling and we're modeling a particular dependent variable, but there is an independent variable that is also determined at the same time. So it's very it's not clearly distinguishable, sometimes simultaneity, but let's look at these examples. And most cooling does that in higher wages. So the dependent variable is wages. And the question is, is more? Is education in general, not just going to MIT and getting low income MIT for sure? You know that

Unknown Speaker  
that's why we're here. Okay,

Speaker 3  
so, but so you want to the dependent variable is income, the independent variable is education and but there is another variable which is ability, which is missing. And the problem is that years of schooling is correlated with ability, so therefore it will lead to endogeneity. People with high ability choose to have more schooling. So this missing line will affect another so it's not really a separate, I mean, but we have this general case of the variable. But this is, you know, like it will explain why there is correlation between included variable and missing variable. That's very important in transportation, in green environment and target behavior. So there are more walking place in area with high density, but people that like to walk are going to reside in area of high density. So if you try to estimate the relationship between like walking trips versus density, you may overestimate the total density. So it's not the density that's only that created the walking trips. It's the people that want to work walk and located in the area of high density. So it doesn't mean that if you're going to change the density, you're going to suddenly have more working types, you will, but it's you're not getting the correct effect if that's what you're doing, if you're only looking at the relationship or addressing density on working groups, that's it. I think these are my examples that I'm going to cover.

Speaker 7  
That's a quick question on the differentiation between the self selection and the emitted variables. The way I understand the explanation is that self self selection is a situation where there's the behavior of the agent we're trying to mention analysis affects it, whereas an emitted variable could be a characteristic of the say it was income and household size, whereas Perhaps some underlying variable will be driving the household size.

Unknown Speaker  
I'm not joining, this is the question, I

Unknown Speaker  
guess I'm just I'm trying to

Speaker 3  
Yeah, difference there between represents simultaneous determination. It's a single situation that will you encounter you need to worry about so and this mode was a story that explains why the omitted variable that there is an important omitted variable, which is an attitude to walking, for example, it is missing, of course, but it's causing endogeneity. Okay, so the solution, the solution is to find instruments, and then we can collect for endogeneity. And that's not easy. That's all the different outcomes. So what does it the definition of an instrument? It's a variable z that is highly correlated with the offensive variable. So X here you know the variable, one of the value in our progression that we determine is endogenous, right? So in the first example, it was y, d minus one. In another example, the y2 we always determine density. We always determine a variable in our model that is the offensive variable, the variable that is calling this variable say this variable is endogenous and so, so this is x is the automatic variable we need to find z such that is highly correlated with x, so z is the predictor of the x, or maybe causing x, but there is a high level of correlation between x and z, but z cannot be correlated with epsilon. So the endogeneity problem is that x and epsilon are correlated. So we want to find z that is correlated with X but not correlated with epsilon. So the expected value of epsilon given z is equal to zero. I mean, that's a strong, strong exogeneity of z, but uncorrelated will be the weak epsilon and z are uncorrelated. And of course, z is not a variable that is already in the model. If it's already in the model and it's causing y, then it's not available in an instrument. So it has to be variable that is not in the model, meaning it is not causing y. So that's why they are called the instrument. The x's are causes right. X's cause y, instrument z are variables that are not causing y, but that satisfy these two conditions. So we're looking for time to estimate the regression and z is not in as an explanatory variable in our model, we need to find a variable that is not in our model that satisfy these two conditions. So if it's not in our model, it's likely, it's likely to be uncorrelated with them absolutely and what we need to have one that is highly correlated with endogenous variable. So the idea is that we use this z to extract and use the portion of x which is not correlated with the algorithm. So we're saying because because because z, the relationship between z and x and so x is correlated with the epsilon, but the part of the x that can be explained by z is not correlated with epsilon, because z is not correlated with epsilon. So that's what we do. So text. And by the way, we will come back to instrument we talk about display choice. There will be a different technique the two stations square, but we will apply the same idea. Yeah, go ahead. You have your question. I You're like Elon Musk, he makes more

Speaker 3  
businesses. In my talks. Okay, so, so that's, that's the definition of instrument. That's a key idea. And we will, you know, we want to estimate the effect of X, but we're using Z, kind of to get rid of the correlation with epsilon so that we can estimate the total factor of x. And how do we do that? So suppose that we're estimating the same signal by the bivariate more than two parameter, vector, one, beta two, and we concluded, and we run a regression, or based on our knowledge, we know that we get omitted variables, or whatever, we determine that x is endogenous, meaning that it is correlated with epsilon. And so if we apply the ordinary square at the bottom, that was the ordinary square estimator, but if we just run regression, then beta two or less will be this will calculate it in this way, right? You know the estimator, but that's a version that we had in lecture one, and we had the simple addition for the same situation, if we can identify an instrument that is not correlated with natural but it's correlated with x, we can have another estimator which is correlated to IV, which is given here. So what happened? You just want to look at the difference multiplying the Y by the Z deviation and multiplying by x by the Z deviation, so the or less, this was basically the covariance of X and Y divided by the variance of x, and here you have the covariance of y and z divided by the covariance of z of x. And in the next class line. Oh, excuse me.

Speaker 3  
Yeah, okay, I saw the proof in the more general occasion, or have the proof coming up here. Okay, sorry about that, so I got confused about the sequence. So, so this is called the idea, I'm sorry. So this is the IV estimator, and in a subsequent slide, I proved that this one is a consistent estimator, that this is biased. We know why it is biased when we the proof of unbiasedness require a condition that is violated, so we don't have unbiasedness and but we'll be able to prove that this one is consistent. Well, this is not okay, so we just, we are going to redo it with a matrix notation. So again, you write a model like that, and x, at least one of the x's is correlated with the epsilon, and so we find Z and Z and epsilon are uncorrelated. So what you can imagine here, this z is not a matrix. Remember, x is a matrix. X is A is a matrix which is n by k. N is the number of observation and K is a number of unknown products. OK, so this is a matrix X, beta, again, is a column vector k by 1y, and epsilon, column vector n by one, and so z. And we will construct z. We will take x and then the column of the offensive variable, the endogenous variable, will replace it with Z, please. Okay, so that's the matrix. Z is constructed by replacing each endogenous variable, each column of x, with an instrumental variable. And so z now is the same. Is an n by k in this notation. And so suppose that we take the model and pre multiply it by this matrix. Z. Can we do that? Yes, we can do that. The dimensionality works. And then we apply these squares for this transformed regression. And if you apply it, we will get, will be like it here we do it, and what we get does that, if you apply regression to this transformation, we get beta equal to z, prime x, inverse z, prime y. So this is just the matrix notation and the equation that I showed you before. So again, you replace the beta hat OLS with beta eight IB equal to this. And now I've shown you the only node that this estimator is inconsistent, bias and inconsistent. I need to show you that this is consistent. It's not unbiased, but consistent. And so first I'll show you for the bivariate model. So beta hat, IP is this equation. You just substitute the model for this Y minus Y bar, and you get this expression. You've done it before. Single thing. Substitute the moment, and we get the beta hat. This gets ID is equal to beta two plus this expression. So if you take the probability limit, then this again, this is a covariance. The top is the covariance of z and epsilon. The bottom is a covariance of z and x. So if you take the probability limit, it's equal to the constant beta, two times the probability limit of that so, so this one, you want this to be a positive constant. We want, we want to be non zero. So this is non zero, some value Q, and this probability limit, you want it to be zero, meaning the Z and the epsilon are correlated, and therefore it is consistent. Beta hat IV is consistent. Whereas in regression, you know, within the premium for the year. We'll have the covadance of x and epsilon, which is not zero, and therefore it will be inconsistent. And here we get the covadance of z and epsilon, where we selected C is such that this goes to zero. And this is just a book. Time limit is the same rule in the multivariate case. And again, we want the covariance. If we selected c such that the covariance is the epsilon is zero, then we are we get consistent. This is consistent estimate, just the same tool. So that's why we want to use we can this. What this demonstrated is that by using instrument, the idea is we can get consistent estimate. We are moving efficiency if you take the tool variable now, and we place it with an instrument, we get a true variable, and we get a consistent estimate, but the variance would be bigger because of this. The variance is calculated by this equation and for the bivariate model, and you can see the for the OLS, this was the variance of the estimator. And here it's multiplied by one divided by the correlation square. And this correlation is a number less than one, so we get greater variance. So there is a loss of so if you look at the sampling distribution it becomes wider, but it converges to the total value. And so this is what happens. It's not you get consistency, but the sampling distribution become a little bit wider depending on this correlation. The greater is this correlation, the lesser is the loss of efficiency you want. So this way you want your correlation to be as high as possible. So there is this terminology, the worst terminology we talk about instrument, distinction between strong instrument and weak instrument, which means the degree of this correlation. So if you have instrument that they have a high degree of correlation with endogenous learning, we do a better job in estimation the experiment more efficient, and this is just in the multivariate case. So we want the correlation between z and between x and z to be as large as possible, positive or negative as we want to be easy to be loved. So one way of making it loud is to have multiple instruments. Why just one? We are going I gave you already two totally well cases. I told you in the simultaneous equation. I said it was x2 and in the value, dependent variable, I said it was x, t minus 1y,

Speaker 2  
t minus one, was it x? Sorry.

Speaker 3  
So we'll talk more about selection. So So, yes, I gave you two examples in the case of simultaneous equation with one, equation with x1 and the second equation they had x2 so x2 are the instrument I'll income, okay, so, so, so the objective is to increase the correlation of the instrument and your offensive variable, and how do we do it by having multiple instruments. So until now, I have for each variable offensive level. I found n1 instrument. I called it V. Suppose that I have different candidates. I have multiple instruments. So in the simultaneous equation was actually an example like this, because we had y2 fancy variable, and we could have many x2 so I mean, maybe I'll come back. So in that case, what we will do? Remember, we have one variable in our equation that is declared as endogenous, and we replaced it with one instrument. Now suppose that we have multiple instruments. So what we are going to do, we are going to apply a technique called two stage least square, and which we will so it's a generalization of what I've shown you so far. Because we take multiple instruments calculate dual regression of the endogenous variable on the left hand side, and the instrument on the right hand side, and then the fit and value will be a combination of instrument will be more will increase the correlation between this will be our instrument, the combination and it will be highly, more highly correlated with x, then each instrument by itself. That's idea, find the optimal combination of instrument that is most highly correlated with the offensive variable. So that's two stages, and these two situations, the situation about the instrument, are clear cut. In other situation, I can tell you, it's definitely defining instrument. And all kind of ideas that I can describe to you as defining instrument in practice. But because you asked me, let me give you some example that, so the positive carbon, often it is the endogenous variables price, right? So you have prices. The question is, why is price endogenous? Usually because quality is omitted, or because demand is a function of price, but price is also a function of demand simultaneity. So price is usually in estimating demand models. Price is usually the problem in transportation modeling of power time can be the problem, because the mind the power time depends on the mind, because condition and then. So, so what can you do? Like, how do let's talk about price. So what can instantly create available and So, typically, like, way to look for it. Here we have examples of the instruments, but for prices different ways. And the basic idea is to take the prices of other countries. Consumers, for example, to other areas nearby, or to competitors, to look for other prices that are not in the model. So I'm modeling the demand for a particular service or good, and I know the price is endogenous. How can I create instruments so often? The idea is to say, okay, maybe prices of other good the same neighborhood as a competitor or different ways of doing so. So that's basically kind of one of the fine instruments with hearings. So we go for this example and come back to this question. I don't mean to like oppose, but like competitors would price their thing,

Speaker 6  
probably based on money price as well. So there's correlation to, like, a competitor's price, to your prices correlated, correlated with your

Speaker 3  
demand. Yeah, competitive price streaming a new demand model. So this competitor price that I'm noting in the demand model, so it cannot be a variable that is already in the model. So it could be a competitor price in another area. So suppose that I'm modeling the demand for cars in Boston. Maybe as an instrument, I will use the prices for the same car in Chicago. That's idea. So the price in Chicago does not affect your demand for cars in Boston. But maybe prices are correlated, right? So it could be the price in Chicago could be the instrument. So maybe the world competitor was not a good source of wealth. Okay?

Speaker 3  
So instrumental variable, so we need at least one instrument for each, endogenous, explanatory. If I don't have enough instrument, I cannot get the consistent estimate if I have just enough instrument for consistent estimation. The meaning if I have for every offensive variable, I get one instrument, then you solve the equation. But now I want to tell the situation where we have more degree instrument per offensive variables, and we use these two state instruments. So that's the most common way of dealing with instruments. So so we combine multiple instruments, construct a new instrument that is a linear combination and maximize the correlation between the new instrument and the endogenous experimental uranium. And we are using all the available information on instruments. That's idea. And we do it in two stages. First, we construct a new instrument that is a linear combination of the original instrument, that's stage one and stage two. We replace the endogenous verbal with a fitted value from the first stage. Okay, so, so again, I mean, I you know what? I will skip this with this slide one and two are kind of complicated. I'll come back to them. I have a secret example. So why did they start? We can flip over, right? So suppose that we have one variable, X, Y variable, and x is endogenous, and we have two instruments, right, z1 and z2 so first you run a regression of x on z1 and z2 Can we do that? Yes, and you get the fitted value, if you call it x hat, and then run a regression of y on x hat, it's a difficult situation, so the later hat related to hat is given by this equation. It just will replace the x with x hat. So the standard error needs to be recalculated, because you can pretend as if x hat is no error, but there is an error from this equation for the calculation of calculation of the beta two is just simply a regression, where you replace the original variable with its fitted value from this regression, and then the quality of the estimate depends on the variance of this theta The smallest it is if this explains the r square, that's the situation where r square metals, because you want the R square of this equation to be as high as possible, because this means you have strong insulin. If the R square of this equation is low, means you may have weak insulin, which means that the variant that beta two, two stage v square would be consistent, but it will have a large variance. So, so that's very that's the basic idea of two stage v square, very easy to apply method, but you need to have disease the pages beforehand that I am going to skip on is just a more general presentation. Says stage one, this regression. So we have on each variable, we put the instrument, we put all the other variable as well. And so if we have green regressor, we include them as well. So when you align this stage one, remember you want to make it as elsewhere, as high as possible. So use all the instruments that you find, plus all the other variable in the model which are not endogenous. And then you do stage two, where the endogenous variable replacement is fitted values and the rest say more than as before. Okay, so that's two stage V squares. This is just two stage v square in matrix notation. And so this is in matrix notation, the auxiliary regression, the stage one regression, right, and then we regress y on x hat, and we know that when we replace x hat with a fitted value, we get a different l term. But this L term is uncorrelated with x hat. So we get, if we apply this square for this equation, this is standard. We know that the assumption is two modes. So now the two cases instrumental, kind of all this I don't have to go to Chicago to suppose that this is a model, again, right? This is a model. It has a dark, deep and flummer, and it has epsilons that have autocorrelation with AR one. So that's the model that we saw last time. So I told you last time that we come back to it and t goes from two to T because therefore t1 we don't have y times zero, so we cannot write the equation. And

Unknown Speaker  
so. So the question is, why humans? One is endogenous, and so, the question is, what are the instruments? So, so why is y t endogenous? Y t minus one endogenous? Because

Speaker 3  
we explained last time. But what are the instruments for Y t minus one? It's x t minus one, because the model written for Y t minus one means that Y t minus one is a function of Y t minus two, because of X t minus one. So, so therefore X t minus one are the clear instrument for Y t minus one, because it affects y t minus one, so it's also correlated with Y t minus one, but it's not correlated with the epsilon, not correlated with this epsilon. So if you can replace Y t minus one with a function of X t minus one, the Mozambique rule, right? So it was not just one. And so stage one is regress y t minus one and X t minus one. This is stage one, and then we continue. Then we can do one, and we can do least squares on this, replace y with y at and now we can apply ordinary least square to this equation. And from that now we get consistent estimate of this assit one so and we can address epsilon tilde head T on epsilon tilde had t minus one, and Calculate the estimate of flow and then maybe applying physical GMs or applying this cocon or procedure, but, but we start the process by first getting dealing with the endogeneity of yt minus one, and that's where we do it. So the instrument here are kind of popular. You have them, if you have the x, you just log them by one period, and they become instruments, and they satisfy all the conditions for instruments. The X t minus one is correlated with Y t minus one and it's uncorrelated. Yes,

Angie.H Moon  
you mentioned that the higher covariance between x and z is, the more efficient the estimator becomes. So in this examples like the Chicago car, the car price with the

Speaker 2  
auto correlation, like, what's the intuition of Y t minus one and X t minus one highly correlated?

Speaker 3  
Well? Is because these are causes of Y t minus t, if beta is equal to zero, then they're not correlated. So to the extent that they are different, the causes of yt minus one these x's and yt minus two. So yeah, it's not going to be perfect correlation, but it is, hopefully sufficiently loud to give us

Speaker 2  
it explains why T more? Right kind of 1x, t minus one

Speaker 3  
explain Y t minus 1y. T minus one is explained by X t minus one. So this is the previous period. Oh, okay. Anyhow, so NY two, so the difference in explanatory power will okay, it's not 225, so on slide, 26 and the next example is simultaneous equation. And simultaneous equation, the instrument for y2 will be x2 let's be the instrument. But I will come back to this example, because I want to talk about this little example identification, so I'll tell you more about it next time Any questions.

Unknown Speaker  
Remember what you said to them? I know, I know that the boy says, but I'm

Unknown Speaker  
not correlated in the points

Unknown Speaker  
Okay.

Transcribed by https://otter.ai
